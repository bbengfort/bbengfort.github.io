---
layout: post
title:  "Pattern Recognition with Nearest Neighbors"
#date:   
categories: tutorials
---

This post is the first in a series that discusses the machine learning methods that I will present in the Georgetown data analytics course. My hope is that I can expose through some tricky JavaScript/visualization the mechanism behind the learning as well as provide some description. These posts will go on DDL's blog.

For kNN the idea is to provide a visualization, that allows you to slide the k parameter to change the model. See [Understanding the Bias Variance Trade-Off](http://scott.fortmann-roe.com/docs/BiasVariance.html) for something very similar. I will also provide accuracy metrics, as well as possibly a ROC curve or something similar. This will hopefully better allow students to understand how kNN works in practice.
