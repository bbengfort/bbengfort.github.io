<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Atomic vs Mutex | Libelli</title><meta name=keywords content><meta name=description content="When implementing Go code, I find myself chasing increased concurrency performance by trying to reduce the number of locks in my code. Often I wonder if using the sync/atomic package is a better choice because I know (as proved by this blog post) that atomics have far more performance than mutexes. The issue is that reading on the internet, including the package documentation itself strongly recommends relying on channels, then mutexes, and finally atomics only if you know what you&rsquo;re doing."><meta name=author content="Benjamin Bengfort"><link rel=canonical href=https://bbengfort.github.io/2022/11/atomic-vs-mutex/><link crossorigin=anonymous href=/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://bbengfort.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bbengfort.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://bbengfort.github.io/icon.png><link rel=apple-touch-icon href=https://bbengfort.github.io/apple-touch-icon-precomposed.png><link rel=mask-icon href=https://bbengfort.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-8096804-11","auto"),ga("send","pageview"))</script><meta property="og:title" content="Atomic vs Mutex"><meta property="og:description" content="When implementing Go code, I find myself chasing increased concurrency performance by trying to reduce the number of locks in my code. Often I wonder if using the sync/atomic package is a better choice because I know (as proved by this blog post) that atomics have far more performance than mutexes. The issue is that reading on the internet, including the package documentation itself strongly recommends relying on channels, then mutexes, and finally atomics only if you know what you&rsquo;re doing."><meta property="og:type" content="article"><meta property="og:url" content="https://bbengfort.github.io/2022/11/atomic-vs-mutex/"><meta property="og:image" content="https://bbengfort.github.io/bear.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-11-26T12:24:25-06:00"><meta property="article:modified_time" content="2022-11-26T12:24:25-06:00"><meta property="og:site_name" content="Libelli"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bbengfort.github.io/bear.png"><meta name=twitter:title content="Atomic vs Mutex"><meta name=twitter:description content="When implementing Go code, I find myself chasing increased concurrency performance by trying to reduce the number of locks in my code. Often I wonder if using the sync/atomic package is a better choice because I know (as proved by this blog post) that atomics have far more performance than mutexes. The issue is that reading on the internet, including the package documentation itself strongly recommends relying on channels, then mutexes, and finally atomics only if you know what you&rsquo;re doing."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://bbengfort.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Atomic vs Mutex","item":"https://bbengfort.github.io/2022/11/atomic-vs-mutex/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Atomic vs Mutex","name":"Atomic vs Mutex","description":"When implementing Go code, I find myself chasing increased concurrency performance by trying to reduce the number of locks in my code. Often I wonder if using the sync/atomic package is a better choice because I know (as proved by this blog post) that atomics have far more performance than mutexes. The issue is that reading on the internet, including the package documentation itself strongly recommends relying on channels, then mutexes, and finally atomics only if you know what you\u0026rsquo;re doing.","keywords":[],"articleBody":"When implementing Go code, I find myself chasing increased concurrency performance by trying to reduce the number of locks in my code. Often I wonder if using the sync/atomic package is a better choice because I know (as proved by this blog post) that atomics have far more performance than mutexes. The issue is that reading on the internet, including the package documentation itself strongly recommends relying on channels, then mutexes, and finally atomics only if you know what you’re doing.\nThe primary difference is that the sync/atomic package uses low level atomic memory primitives provided directly by CPU instructions but without any ordering guarantees. Channels and mutexes guarantee the strict order of accesses to values being shared by go routines, and since these semantics are what we expect, it is often the better choice to use mutexes and channels. However, if you’re just trying to ensure that a single operation happens correctly in isolation (such as tracking statistics), or if you’re building concurrency primitives from scratch for advanced algorithms, then using atomics makes sense.\nAnd here’s why it makes sense:\nBenchmarkCounterInc/Atomic-10 170998743\t6.881 ns/op\t1162.54 MB/s\t0 B/op\t0 allocs/op BenchmarkCounterInc/Mutex-10 65349984\t18.50 ns/op\t432.34 MB/s\t0 B/op\t0 allocs/op BenchmarkCounterLoad/Atomic-10 1000000000\t0.5131 ns/op\t15590.98 MB/s\t0 B/op\t0 allocs/op BenchmarkCounterLoad/Mutex-10 87413383\t13.72 ns/op\t583.05 MB/s\t0 B/op\t0 allocs/op On my Macbook Pro, using atomics to keep track of a counter is 3x faster for writes and and 26x faster for reads.\nSources Atomic Package Documentation StackOverflow: Is there a difference in Go between a counter using atomic operations and one using a mutex? Complete Code The complete code and benchmark results on gist can be found below:\n","wordCount":"280","inLanguage":"en","datePublished":"2022-11-26T12:24:25-06:00","dateModified":"2022-11-26T12:24:25-06:00","author":{"@type":"Person","name":"Benjamin Bengfort"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bbengfort.github.io/2022/11/atomic-vs-mutex/"},"publisher":{"@type":"Organization","name":"Libelli","logo":{"@type":"ImageObject","url":"https://bbengfort.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://bbengfort.github.io accesskey=h title="Libelli (Alt + H)"><img src=https://bbengfort.github.io/icon.png alt aria-label=logo height=35>Libelli</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://bbengfort.github.io/archive/ title=archive><span>archive</span></a></li><li><a href=https://bbengfort.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://bbengfort.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://bbengfort.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://bbengfort.github.io>Home</a>&nbsp;»&nbsp;<a href=https://bbengfort.github.io/posts/>Posts</a></div><h1 class=post-title>Atomic vs Mutex</h1><div class=post-meta><span title='2022-11-26 12:24:25 -0600 -0600'>November 26, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;280 words&nbsp;·&nbsp;Benjamin Bengfort&nbsp;|&nbsp;<a href=https://github.com/bbengfort/bbengfort.github.io/tree/main/content/posts/2022-11-26-atomic-vs-mutex.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>When implementing Go code, I find myself chasing increased concurrency performance by trying to reduce the number of locks in my code. Often I wonder if using the <code>sync/atomic</code> package is a better choice because I know (as proved by this blog post) that atomics have far more performance than mutexes. The issue is that reading on the internet, including the <a href=https://pkg.go.dev/sync/atomic>package documentation</a> itself strongly recommends relying on channels, then mutexes, and finally atomics <em>only if you know what you&rsquo;re doing</em>.</p><p>The primary difference is that the <code>sync/atomic</code> package uses low level atomic memory primitives provided directly by CPU instructions but without any ordering guarantees. Channels and mutexes guarantee the strict order of accesses to values being shared by go routines, and since these semantics are what we expect, it is often the better choice to use mutexes and channels. However, if you&rsquo;re just trying to ensure that a single operation happens correctly in isolation (such as tracking statistics), or if you&rsquo;re building concurrency primitives from scratch for advanced algorithms, then using atomics makes sense.</p><p>And here&rsquo;s why it makes sense:</p><pre tabindex=0><code>BenchmarkCounterInc/Atomic-10         	170998743	         6.881 ns/op	1162.54 MB/s	       0 B/op	       0 allocs/op
BenchmarkCounterInc/Mutex-10          	65349984	        18.50 ns/op	 432.34 MB/s	       0 B/op	       0 allocs/op
BenchmarkCounterLoad/Atomic-10        	1000000000	         0.5131 ns/op	15590.98 MB/s	       0 B/op	       0 allocs/op
BenchmarkCounterLoad/Mutex-10         	87413383	        13.72 ns/op	 583.05 MB/s	       0 B/op	       0 allocs/op
</code></pre><p>On my Macbook Pro, using atomics to keep track of a counter is 3x faster for writes and and 26x faster for reads.</p><h2 id=sources>Sources<a hidden class=anchor aria-hidden=true href=#sources>#</a></h2><ul><li><a href=https://pkg.go.dev/sync/atomic>Atomic Package Documentation</a></li><li><a href=https://stackoverflow.com/questions/47445344/is-there-a-difference-in-go-between-a-counter-using-atomic-operations-and-one-us>StackOverflow: Is there a difference in Go between a counter using atomic operations and one using a mutex?</a></li></ul><h2 id=complete-code>Complete Code<a hidden class=anchor aria-hidden=true href=#complete-code>#</a></h2><p>The complete code and benchmark results on <a href=https://gist.github.com/bbengfort/44308aeab2d6def5899c7e34d189e945>gist</a> can be found below:</p><script type=application/javascript src=https://gist.github.com/bbengfort/44308aeab2d6def5899c7e34d189e945.js></script></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://bbengfort.github.io/2023/05/faster-protocol-buffer-serialization/><span class=title>« Prev</span><br><span>Faster Protocol Buffer Serialization</span></a>
<a class=next href=https://bbengfort.github.io/2021/03/nonlinear-workflow-planning-software-projects/><span class=title>Next »</span><br><span>Nonlinear Workflow for Planning Software Projects</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://bbengfort.github.io>Libelli</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>