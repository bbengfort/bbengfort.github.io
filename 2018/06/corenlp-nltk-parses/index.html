<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Syntax Parsing with CoreNLP and NLTK | Libelli</title><meta name=keywords content><meta name=description content="Syntactic parsing is a technique by which segmented, tokenized, and part-of-speech tagged text is assigned a structure that reveals the relationships between tokens governed by syntax rules, e.g. by grammars. Consider the sentence:
The factory employs 12.8 percent of Bradford County.
A syntax parse produces a tree that might help us understand that the subject of the sentence is &ldquo;the factory&rdquo;, the predicate is &ldquo;employs&rdquo;, and the target is &ldquo;12.8 percent&rdquo;, which in turn is modified by &ldquo;Bradford County&rdquo;."><meta name=author content="Benjamin Bengfort"><link rel=canonical href=https://bbengfort.github.io/2018/06/corenlp-nltk-parses/><link crossorigin=anonymous href=/assets/css/stylesheet.min.2d6dbfc6e0f8a1db1c9d082a76dc11d094328cf63f247bbc2421dfaa7f2bb170.css integrity="sha256-LW2/xuD4odscnQgqdtwR0JQyjPY/JHu8JCHfqn8rsXA=" rel="preload stylesheet" as=style><link rel=preload href=/icon.png as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://bbengfort.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bbengfort.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://bbengfort.github.io/icon.png><link rel=apple-touch-icon href=https://bbengfort.github.io/apple-touch-icon-precomposed.png><link rel=mask-icon href=https://bbengfort.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.105.0"><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-8096804-11","auto"),ga("send","pageview"))</script><meta property="og:title" content="Syntax Parsing with CoreNLP and NLTK"><meta property="og:description" content="Syntactic parsing is a technique by which segmented, tokenized, and part-of-speech tagged text is assigned a structure that reveals the relationships between tokens governed by syntax rules, e.g. by grammars. Consider the sentence:
The factory employs 12.8 percent of Bradford County.
A syntax parse produces a tree that might help us understand that the subject of the sentence is &ldquo;the factory&rdquo;, the predicate is &ldquo;employs&rdquo;, and the target is &ldquo;12.8 percent&rdquo;, which in turn is modified by &ldquo;Bradford County&rdquo;."><meta property="og:type" content="article"><meta property="og:url" content="https://bbengfort.github.io/2018/06/corenlp-nltk-parses/"><meta property="og:image" content="https://bbengfort.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-06-22T14:38:21+00:00"><meta property="article:modified_time" content="2018-06-22T14:38:21+00:00"><meta property="og:site_name" content="Libelli"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bbengfort.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Syntax Parsing with CoreNLP and NLTK"><meta name=twitter:description content="Syntactic parsing is a technique by which segmented, tokenized, and part-of-speech tagged text is assigned a structure that reveals the relationships between tokens governed by syntax rules, e.g. by grammars. Consider the sentence:
The factory employs 12.8 percent of Bradford County.
A syntax parse produces a tree that might help us understand that the subject of the sentence is &ldquo;the factory&rdquo;, the predicate is &ldquo;employs&rdquo;, and the target is &ldquo;12.8 percent&rdquo;, which in turn is modified by &ldquo;Bradford County&rdquo;."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://bbengfort.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Syntax Parsing with CoreNLP and NLTK","item":"https://bbengfort.github.io/2018/06/corenlp-nltk-parses/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Syntax Parsing with CoreNLP and NLTK","name":"Syntax Parsing with CoreNLP and NLTK","description":"Syntactic parsing is a technique by which segmented, tokenized, and part-of-speech tagged text is assigned a structure that reveals the relationships between tokens governed by syntax rules, e.g. by grammars. Consider the sentence:\nThe factory employs 12.8 percent of Bradford County.\nA syntax parse produces a tree that might help us understand that the subject of the sentence is \u0026ldquo;the factory\u0026rdquo;, the predicate is \u0026ldquo;employs\u0026rdquo;, and the target is \u0026ldquo;12.8 percent\u0026rdquo;, which in turn is modified by \u0026ldquo;Bradford County\u0026rdquo;.","keywords":[],"articleBody":"Syntactic parsing is a technique by which segmented, tokenized, and part-of-speech tagged text is assigned a structure that reveals the relationships between tokens governed by syntax rules, e.g. by grammars. Consider the sentence:\nThe factory employs 12.8 percent of Bradford County.\nA syntax parse produces a tree that might help us understand that the subject of the sentence is “the factory”, the predicate is “employs”, and the target is “12.8 percent”, which in turn is modified by “Bradford County”. Syntax parses are often a first step toward deep information extraction or semantic understanding of text. Note however, that syntax parsing methods suffer from structural ambiguity, that is the possibility that there exists more than one correct parse for a given sentence. Attempting to select the most likely parse for a sentence is incredibly difficult.\nThe best general syntax parser that exists for English, Arabic, Chinese, French, German, and Spanish is currently the blackbox parser found in Stanford’s CoreNLP library. This parser is a Java library, however, and requires Java 1.8 to be installed. Luckily it also comes with a server that can be run and accessed from Python using NLTK 3.2.3 or later. Once you have downloaded the JAR files from the CoreNLP download page and installed Java 1.8 as well as pip installed nltk, you can run the server as follows:\nfrom nltk.parse.corenlp import CoreNLPServer # The server needs to know the location of the following files: # - stanford-corenlp-X.X.X.jar # - stanford-corenlp-X.X.X-models.jar STANFORD = os.path.join(\"models\", \"stanford-corenlp-full-2018-02-27\") # Create the server server = CoreNLPServer( os.path.join(STANFORD, \"stanford-corenlp-3.9.1.jar\"), os.path.join(STANFORD, \"stanford-corenlp-3.9.1-models.jar\"), ) # Start the server in the background server.start() The server needs to know the location of the JAR files you downloaded, either by adding them to your Java $CLASSPATH or like me, storing them in a models directory that you can access from your project. When you start the server, it runs in the background, ready for parsing.\nTo get constituency parses from the server, instantiate a CoreNLPParser and parse raw text as follows:\nfrom nltk.parse.corenlpnltk.pa import CoreNLPParser parser = CoreNLPParser() parse = next(parser.raw_parse(\"I put the book in the box on the table.\")) If you’re in a Jupyter notebook, the tree will be drawn as above. Note that the CoreNLPParser can take a URL to the CoreNLP server, so if you’re deploying this in production, you can run the server in a docker container, etc. and access it for multiple parses. The raw_parse method expects a single sentence as a string; you can also use the parse method to pass in tokenized and tagged text using other NLTK methods. Parses are also handy for identifying questions:\nnext(parser.raw_parse(\"What is the longest river in the world?\")) Note the SBARQ representing the question; this data can be used to create a classifier that can detect what type of question is being asked, which can then in turn be used to transform the question into a database query!\nI should also point out why we’re using next(); the parser actually returns a generator of parses, starting with the most likely. By using next, we’re selecting only the first, most likely parse.\nConstituency parses are deep and contain a lot of information, but often dependency parses are more useful for text analytics and information extraction. To get a Stanford dependency parse with Python:\nfrom nltk.parse.corenlp import CoreNLPDependencyParser parser = CoreNLPDependencyParser() parse = next(parser.raw_parse(\"I put the book in the box on the table.\")) Once you’re done parsing, don’t forget to stop the server!\n# Stop the CoreNLP server server.stop() To ensure that the server is stopped even when an exception occurs, you can also use the CoreNLPServer context manager as follows:\njars = ( \"stanford-corenlp-3.9.1.jar\", \"stanford-corenlp-3.9.1-models.jar\" ) with CoreNLPServer(*jars): parser = CoreNLPParser() text = \"The runner scored from second on a base hit\" parse = next(parser.parse_text(text)) parse.draw() Note that the parse_text function in the above code allows a string to be passed that might contain multiple sentences and returns a parse for each sentence it segments. Additionally the tokenize and tag methods can be used on the parser to get the Stanford part of speech tags from the text.\nUnfortunately there isn’t much documentation on this, but for more check out the NLTK CoreNLP API documentation.\n","wordCount":"700","inLanguage":"en","datePublished":"2018-06-22T14:38:21Z","dateModified":"2018-06-22T14:38:21Z","author":{"@type":"Person","name":"Benjamin Bengfort"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bbengfort.github.io/2018/06/corenlp-nltk-parses/"},"publisher":{"@type":"Organization","name":"Libelli","logo":{"@type":"ImageObject","url":"https://bbengfort.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://bbengfort.github.io accesskey=h title="Libelli (Alt + H)"><img src=/icon.png alt=logo aria-label=logo height=35>Libelli</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://bbengfort.github.io/archive/ title=archive><span>archive</span></a></li><li><a href=https://bbengfort.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://bbengfort.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://bbengfort.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Syntax Parsing with CoreNLP and NLTK</h1><div class=post-meta>June 22, 2018&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Benjamin Bengfort</div></header><div class=post-content><p>Syntactic parsing is a technique by which segmented, tokenized, and part-of-speech tagged text is assigned a structure that reveals the relationships between tokens governed by syntax rules, e.g. by grammars. Consider the sentence:</p><blockquote><p>The factory employs 12.8 percent of Bradford County.</p></blockquote><p>A syntax parse produces a tree that might help us understand that the subject of the sentence is &ldquo;the factory&rdquo;, the predicate is &ldquo;employs&rdquo;, and the target is &ldquo;12.8 percent&rdquo;, which in turn is modified by &ldquo;Bradford County&rdquo;. Syntax parses are often a first step toward deep information extraction or semantic understanding of text. Note however, that syntax parsing methods suffer from <em>structural ambiguity</em>, that is the possibility that there exists more than one correct parse for a given sentence. Attempting to select the most likely parse for a sentence is incredibly difficult.</p><p>The best general syntax parser that exists for English, Arabic, Chinese, French, German, and Spanish is currently the blackbox parser found in <a href=https://stanfordnlp.github.io/CoreNLP/>Stanford&rsquo;s CoreNLP library</a>. This parser is a Java library, however, and requires Java 1.8 to be installed. Luckily it also comes with a server that can be run and accessed from Python using NLTK 3.2.3 or later. Once you have downloaded the JAR files from the CoreNLP download page and installed Java 1.8 as well as pip installed nltk, you can run the server as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> nltk.parse.corenlp <span style=color:#f92672>import</span> CoreNLPServer
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># The server needs to know the location of the following files:</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   - stanford-corenlp-X.X.X.jar</span>
</span></span><span style=display:flex><span><span style=color:#75715e>#   - stanford-corenlp-X.X.X-models.jar</span>
</span></span><span style=display:flex><span>STANFORD <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(<span style=color:#e6db74>&#34;models&#34;</span>, <span style=color:#e6db74>&#34;stanford-corenlp-full-2018-02-27&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Create the server</span>
</span></span><span style=display:flex><span>server <span style=color:#f92672>=</span> CoreNLPServer(
</span></span><span style=display:flex><span>   os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(STANFORD, <span style=color:#e6db74>&#34;stanford-corenlp-3.9.1.jar&#34;</span>),
</span></span><span style=display:flex><span>   os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(STANFORD, <span style=color:#e6db74>&#34;stanford-corenlp-3.9.1-models.jar&#34;</span>),
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Start the server in the background</span>
</span></span><span style=display:flex><span>server<span style=color:#f92672>.</span>start()
</span></span></code></pre></div><p>The server needs to know the location of the JAR files you downloaded, either by adding them to your Java <code>$CLASSPATH</code> or like me, storing them in a models directory that you can access from your project. When you start the server, it runs in the background, ready for parsing.</p><p>To get constituency parses from the server, instantiate a <code>CoreNLPParser</code> and parse raw text as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span>  nltk.parse.corenlpnltk.pa  <span style=color:#f92672>import</span> CoreNLPParser
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>parser <span style=color:#f92672>=</span> CoreNLPParser()
</span></span><span style=display:flex><span>parse <span style=color:#f92672>=</span> next(parser<span style=color:#f92672>.</span>raw_parse(<span style=color:#e6db74>&#34;I put the book in the box on the table.&#34;</span>))
</span></span></code></pre></div><p><img loading=lazy src=/images/2018-06-22-syntax-parse.png alt="Syntax Parse"></p><p>If you&rsquo;re in a Jupyter notebook, the tree will be drawn as above. Note that the <code>CoreNLPParser</code> can take a URL to the CoreNLP server, so if you&rsquo;re deploying this in production, you can run the server in a docker container, etc. and access it for multiple parses. The <code>raw_parse</code> method expects a single sentence as a string; you can also use the <code>parse</code> method to pass in tokenized and tagged text using other NLTK methods. Parses are also handy for identifying questions:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>next(parser<span style=color:#f92672>.</span>raw_parse(<span style=color:#e6db74>&#34;What is the longest river in the world?&#34;</span>))
</span></span></code></pre></div><p><img loading=lazy src=/images/2018-06-22-syntax-parse-question.png alt="Question Syntax Parse"></p><p>Note the <code>SBARQ</code> representing the question; this data can be used to create a classifier that can detect what type of question is being asked, which can then in turn be used to transform the question into a database query!</p><p>I should also point out why we&rsquo;re using <code>next()</code>; the parser actually returns a generator of parses, starting with the most likely. By using <code>next</code>, we&rsquo;re selecting only the first, most likely parse.</p><p>Constituency parses are deep and contain a lot of information, but often dependency parses are more useful for text analytics and information extraction. To get a Stanford dependency parse with Python:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> nltk.parse.corenlp <span style=color:#f92672>import</span> CoreNLPDependencyParser
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>parser <span style=color:#f92672>=</span> CoreNLPDependencyParser()
</span></span><span style=display:flex><span>parse <span style=color:#f92672>=</span> next(parser<span style=color:#f92672>.</span>raw_parse(<span style=color:#e6db74>&#34;I put the book in the box on the table.&#34;</span>))
</span></span></code></pre></div><p><img loading=lazy src=/images/2018-06-22-dependency-parse.svg alt="Dependency Parse"></p><p>Once you&rsquo;re done parsing, don&rsquo;t forget to stop the server!</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Stop the CoreNLP server</span>
</span></span><span style=display:flex><span>server<span style=color:#f92672>.</span>stop()
</span></span></code></pre></div><p>To ensure that the server is stopped even when an exception occurs, you can also use the <code>CoreNLPServer</code> context manager as follows:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>jars <span style=color:#f92672>=</span> (
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;stanford-corenlp-3.9.1.jar&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;stanford-corenlp-3.9.1-models.jar&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>with</span> CoreNLPServer(<span style=color:#f92672>*</span>jars):
</span></span><span style=display:flex><span>    parser <span style=color:#f92672>=</span> CoreNLPParser()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    text <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;The runner scored from second on a base hit&#34;</span>
</span></span><span style=display:flex><span>    parse <span style=color:#f92672>=</span> next(parser<span style=color:#f92672>.</span>parse_text(text))
</span></span><span style=display:flex><span>    parse<span style=color:#f92672>.</span>draw()
</span></span></code></pre></div><p>Note that the <code>parse_text</code> function in the above code allows a string to be passed that might contain multiple sentences and returns a parse for each sentence it segments. Additionally the <code>tokenize</code> and <code>tag</code> methods can be used on the parser to get the Stanford part of speech tags from the text.</p><p>Unfortunately there isn&rsquo;t much documentation on this, but for more check out the <a href=http://www.nltk.org/_modules/nltk/parse/corenlp.html>NLTK CoreNLP API documentation</a>.</p></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://bbengfort.github.io>Libelli</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById("menu");menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>