<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blast Throughput | Libelli</title><meta name=keywords content><meta name=description content="Blast throughput is what we call a throughput measurement such that N requests are simultaneously sent to the server and the duration to receive responses for all N requests is recorded. The throughput is computed as N/duration where duration is in seconds. This is the typical and potentially correct way to measure throughput from a client to a server, however issues do arise in distributed systems land:
the requests must all originate from a single client high latency response outliers can skew results you must be confident that N is big enough to max out the server N mustn&rsquo;t be so big as to create non-server related bottlenecks."><meta name=author content="Benjamin Bengfort"><link rel=canonical href=https://bbengfort.github.io/2018/09/blast-throughput/><link crossorigin=anonymous href=/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://bbengfort.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bbengfort.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://bbengfort.github.io/icon.png><link rel=apple-touch-icon href=https://bbengfort.github.io/apple-touch-icon-precomposed.png><link rel=mask-icon href=https://bbengfort.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-8096804-11","auto"),ga("send","pageview"))</script><meta property="og:title" content="Blast Throughput"><meta property="og:description" content="Blast throughput is what we call a throughput measurement such that N requests are simultaneously sent to the server and the duration to receive responses for all N requests is recorded. The throughput is computed as N/duration where duration is in seconds. This is the typical and potentially correct way to measure throughput from a client to a server, however issues do arise in distributed systems land:
the requests must all originate from a single client high latency response outliers can skew results you must be confident that N is big enough to max out the server N mustn&rsquo;t be so big as to create non-server related bottlenecks."><meta property="og:type" content="article"><meta property="og:url" content="https://bbengfort.github.io/2018/09/blast-throughput/"><meta property="og:image" content="https://bbengfort.github.io/bear.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-09-26T17:06:24+00:00"><meta property="article:modified_time" content="2018-09-26T17:06:24+00:00"><meta property="og:site_name" content="Libelli"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bbengfort.github.io/bear.png"><meta name=twitter:title content="Blast Throughput"><meta name=twitter:description content="Blast throughput is what we call a throughput measurement such that N requests are simultaneously sent to the server and the duration to receive responses for all N requests is recorded. The throughput is computed as N/duration where duration is in seconds. This is the typical and potentially correct way to measure throughput from a client to a server, however issues do arise in distributed systems land:
the requests must all originate from a single client high latency response outliers can skew results you must be confident that N is big enough to max out the server N mustn&rsquo;t be so big as to create non-server related bottlenecks."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://bbengfort.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Blast Throughput","item":"https://bbengfort.github.io/2018/09/blast-throughput/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Blast Throughput","name":"Blast Throughput","description":"Blast throughput is what we call a throughput measurement such that N requests are simultaneously sent to the server and the duration to receive responses for all N requests is recorded. The throughput is computed as N/duration where duration is in seconds. This is the typical and potentially correct way to measure throughput from a client to a server, however issues do arise in distributed systems land:\nthe requests must all originate from a single client high latency response outliers can skew results you must be confident that N is big enough to max out the server N mustn\u0026rsquo;t be so big as to create non-server related bottlenecks.","keywords":[],"articleBody":"Blast throughput is what we call a throughput measurement such that N requests are simultaneously sent to the server and the duration to receive responses for all N requests is recorded. The throughput is computed as N/duration where duration is in seconds. This is the typical and potentially correct way to measure throughput from a client to a server, however issues do arise in distributed systems land:\nthe requests must all originate from a single client high latency response outliers can skew results you must be confident that N is big enough to max out the server N mustn’t be so big as to create non-server related bottlenecks. In this post I’ll discuss my implementation of the blast workload as well as an issue that came up with many concurrent connections in gRPC. This led me down the path to use one connection to do blast throughput testing, which led to other issues, which I’ll discuss later.\nFirst, let’s suppose that we have a gRPC service that defines a unary RPC with a Put() interface that allows the storage of a string key and a bytes value with protocol buffers. The blast throughput implementation is as follows:\nThis is a lot of code to go through but the key parts of this are as follows:\nAs much work as possible is done before executing the blast, e.g. creating request objects and connecting the clients to the server. Synchronization is achieved through arrays of length N - no channels or locks are used for reporting purposes. The only thing each blast operation executes is the creation of a context and sending the request to the server. I created a simple server that wrapped a map[string][]byte with a sync.RWMutex and implemented the Put service. It’s not high performance, sure, but it should highlight how well Blast works as well as the performance of a minimal gRPC server, the results surprised me:\nThe top graph shows the throughput, a terrible 4500 ops/second for only 250 blasted requests, and worse, after 250 requests the throughput drops to nothing, because as you can see from the bottom graph, the failures start to increase.\nPrinting out the errors I was getting rpc error: code = Unavailable desc = transport is closing errors from gRPC. All 1000 clients successfully connected, but then could not make requests.\nThe fix, as mentioned on line 41 was to replace the client per request with a single client (or possible a handful of clients that are used in a round-robin fashion by each request). This improved things significantly:\nNow we’re getting 30,000 puts per second, which is closer to what I would expect from gRPC’s Unary RPC. However, using a single client does pose some issues:\nThe client must be thread safe when making requests, which could add additional overhead to the throughput computation. Dealing with redirects or other server-side errors may become impossible with a single client blast throughput measurement. How do you balance the blast against multiple servers? The complete implementation of Blast and the server can be found at github.com/bbengfort/speedmap in the server-blast branch in the server folder.\nNote that I just found strest-grpc, which I’m interested in figuring out how it matches up with this assesment and blog post.\nIn a later post, I’ll discuss how we implement sustained throughput - where we have multiple clients continuously writing to the system and we measure throughput server-side.\n","wordCount":"569","inLanguage":"en","datePublished":"2018-09-26T17:06:24Z","dateModified":"2018-09-26T17:06:24Z","author":{"@type":"Person","name":"Benjamin Bengfort"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bbengfort.github.io/2018/09/blast-throughput/"},"publisher":{"@type":"Organization","name":"Libelli","logo":{"@type":"ImageObject","url":"https://bbengfort.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://bbengfort.github.io accesskey=h title="Libelli (Alt + H)"><img src=https://bbengfort.github.io/icon.png alt aria-label=logo height=35>Libelli</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://bbengfort.github.io/archive/ title=archive><span>archive</span></a></li><li><a href=https://bbengfort.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://bbengfort.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://bbengfort.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://bbengfort.github.io>Home</a>&nbsp;»&nbsp;<a href=https://bbengfort.github.io/posts/>Posts</a></div><h1 class=post-title>Blast Throughput</h1><div class=post-meta><span title='2018-09-26 17:06:24 +0000 UTC'>September 26, 2018</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;569 words&nbsp;·&nbsp;Benjamin Bengfort&nbsp;|&nbsp;<a href=https://github.com/bbengfort/bbengfort.github.io/tree/main/content/posts/2018-09-26-blast-throughput.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>Blast throughput is what we call a throughput measurement such that N requests are simultaneously sent to the server and the duration to receive responses for all N requests is recorded. The throughput is computed as <code>N/duration</code> where duration is in seconds. This is the typical and potentially correct way to measure throughput from a client to a server, however issues do arise in distributed systems land:</p><ol><li>the requests must all originate from a single client</li><li>high latency response outliers can skew results</li><li>you must be confident that N is big enough to max out the server</li><li>N mustn&rsquo;t be so big as to create non-server related bottlenecks.</li></ol><p>In this post I&rsquo;ll discuss my implementation of the blast workload as well as an issue that came up with many concurrent connections in gRPC. This led me down the path to use one connection to do blast throughput testing, which led to other issues, which I&rsquo;ll discuss later.</p><p>First, let&rsquo;s suppose that we have a gRPC service that defines a unary RPC with a <code>Put()</code> interface that allows the storage of a string key and a bytes value with protocol buffers. The blast throughput implementation is as follows:</p><script type=application/javascript src=https://gist.github.com/bbengfort/6df90d9a684e9a05e8818d0a14c98e9f.js></script><p>This is a lot of code to go through but the key parts of this are as follows:</p><ol><li>As much work as possible is done before executing the blast, e.g. creating request objects and connecting the clients to the server.</li><li>Synchronization is achieved through arrays of length N - no channels or locks are used for reporting purposes.</li><li>The only thing each blast operation executes is the creation of a context and sending the request to the server.</li></ol><p>I created a simple server that wrapped a <code>map[string][]byte</code> with a <code>sync.RWMutex</code> and implemented the <code>Put</code> service. It&rsquo;s not high performance, sure, but it should highlight how well Blast works as well as the performance of a minimal gRPC server, the results surprised me:</p><p><img loading=lazy src=/images/2018-09-26-blast-syncmap-mc.png alt="Multi-Client Blast Results"></p><p>The top graph shows the throughput, a <em>terrible</em> 4500 ops/second for only 250 blasted requests, and worse, after 250 requests the throughput drops to nothing, because as you can see from the bottom graph, the failures start to increase.</p><p>Printing out the errors I was getting <code>rpc error: code = Unavailable desc = transport is closing</code> errors from gRPC. All 1000 clients successfully connected, but then could not make requests.</p><p>The fix, as mentioned on <a href=https://gist.github.com/bbengfort/6df90d9a684e9a05e8818d0a14c98e9f#file-bench-go-L41>line 41</a> was to replace the client per request with a single client (or possible a handful of clients that are used in a round-robin fashion by each request). This improved things significantly:</p><p><img loading=lazy src=/images/2018-09-26-blast-syncmap-sc.png alt="Single-Client Blast Results"></p><p>Now we&rsquo;re getting 30,000 puts per second, which is closer to what I would expect from gRPC&rsquo;s Unary RPC. However, using a single client does pose some issues:</p><ol><li>The client must be thread safe when making requests, which could add additional overhead to the throughput computation.</li><li>Dealing with redirects or other server-side errors may become impossible with a single client blast throughput measurement.</li><li>How do you balance the blast against multiple servers?</li></ol><p>The complete implementation of Blast and the server can be found at <a href=https://github.com/bbengfort/speedmap/tree/server-blast>github.com/bbengfort/speedmap</a> in the <code>server-blast</code> branch in the <code>server</code> folder.</p><p>Note that I just found <a href=https://hub.docker.com/r/buoyantio/strest-grpc/>strest-grpc</a>, which I&rsquo;m interested in figuring out how it matches up with this assesment and blog post.</p><p>In a later post, I&rsquo;ll discuss how we implement sustained throughput - where we have multiple clients continuously writing to the system and we measure throughput server-side.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://bbengfort.github.io/2019/02/mount-ebs-volume/><span class=title>« Prev</span><br><span>Mount an EBS volume</span></a>
<a class=next href=https://bbengfort.github.io/2018/09/go-testing-notes/><span class=title>Next »</span><br><span>Go Testing Notes</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://bbengfort.github.io>Libelli</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>