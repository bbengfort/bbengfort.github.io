<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Streaming Remote Throughput | Libelli</title>
<meta name=keywords content><meta name=description content="In order to improve the performance of asynchronous message passing in Alia, I&rsquo;m using gRPC bidirectional streaming to create the peer to peer connections. When the replica is initialized it creates a remote connection to each of its peers that lives in its own go routine; any other thread can send messages by passing them to that go routine through a channel, replies are then dispatched via another channel, directed to the thread via an actor dispatching model."><meta name=author content="Benjamin Bengfort"><link rel=canonical href=https://bbengfort.github.io/2018/09/streaming-remote-throughput/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://bbengfort.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bbengfort.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://bbengfort.github.io/icon.png><link rel=apple-touch-icon href=https://bbengfort.github.io/apple-touch-icon-precomposed.png><link rel=mask-icon href=https://bbengfort.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://bbengfort.github.io/2018/09/streaming-remote-throughput/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-D3BE7EHHVP"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D3BE7EHHVP")}</script><meta property="og:title" content="Streaming Remote Throughput"><meta property="og:description" content="In order to improve the performance of asynchronous message passing in Alia, I&rsquo;m using gRPC bidirectional streaming to create the peer to peer connections. When the replica is initialized it creates a remote connection to each of its peers that lives in its own go routine; any other thread can send messages by passing them to that go routine through a channel, replies are then dispatched via another channel, directed to the thread via an actor dispatching model."><meta property="og:type" content="article"><meta property="og:url" content="https://bbengfort.github.io/2018/09/streaming-remote-throughput/"><meta property="og:image" content="https://bbengfort.github.io/bear.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-09-11T15:19:17+00:00"><meta property="article:modified_time" content="2018-09-11T15:19:17+00:00"><meta property="og:site_name" content="Libelli"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bbengfort.github.io/bear.png"><meta name=twitter:title content="Streaming Remote Throughput"><meta name=twitter:description content="In order to improve the performance of asynchronous message passing in Alia, I&rsquo;m using gRPC bidirectional streaming to create the peer to peer connections. When the replica is initialized it creates a remote connection to each of its peers that lives in its own go routine; any other thread can send messages by passing them to that go routine through a channel, replies are then dispatched via another channel, directed to the thread via an actor dispatching model."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://bbengfort.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Streaming Remote Throughput","item":"https://bbengfort.github.io/2018/09/streaming-remote-throughput/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Streaming Remote Throughput","name":"Streaming Remote Throughput","description":"In order to improve the performance of asynchronous message passing in Alia, I\u0026rsquo;m using gRPC bidirectional streaming to create the peer to peer connections. When the replica is initialized it creates a remote connection to each of its peers that lives in its own go routine; any other thread can send messages by passing them to that go routine through a channel, replies are then dispatched via another channel, directed to the thread via an actor dispatching model.\n","keywords":[],"articleBody":"In order to improve the performance of asynchronous message passing in Alia, I’m using gRPC bidirectional streaming to create the peer to peer connections. When the replica is initialized it creates a remote connection to each of its peers that lives in its own go routine; any other thread can send messages by passing them to that go routine through a channel, replies are then dispatched via another channel, directed to the thread via an actor dispatching model.\nThis post is about the performance of the remote sending go routine, particularly with respect to how many threads that routine is. Here is some basic stub code for the messenger go routine that listens for incoming messages on a buffered channel, and sends them to the remote via the stream:\nfunc (r *Remote) messenger() { // Attempt to establish a connection to the remote peer var err error if err = r.connect(); err != nil { out.Warn(err.Error()) } // Send all messages in the order they arrive on the channel for msg := range r.messages { // If we're not online try to re-establish the connection if !r.online { if err = r.connect(); err != nil { out.Warn( \"dropped %s message to %s (%s): could not connect\", msg.Type, r.Name, r.Endpoint() ) // close the connection and go to the next message r.close() continue } } // Send the message on the remote stream if err = r.stream.Send(msg); err != nil { out.Warn( \"dropped %s message to %s (%s): could not send: %s\", msg.Type, r.Name, r.Endpoint(), err.Error() ) // go offline if there was an error sending a message r.close() continue } // But now how do we receive the reply? } } The question is, how do we receive the reply from the remote?\nIn sync mode, we can simply receive the reply before we send the next message. This has the benefit of ensuring that there is no further synchronization required on connect and close, however as shown in the graph below, it does not perform well at all.\nIn async mode, we can launch another go routine to handle all the incoming requests and dispatch them:\nfunc (r *Remote) listener() { for { if r.online { var ( err error rep *pb.PeerReply ) if rep, err = r.stream.Recv(); err != nil { out.Warn( \"no response from %s (%s): %s\", r.Name, r.Endpoint(), err ) return } r.Dispatcher.Dispatch(events.New(rep.EventType(), r, rep)) } } } This does much better in terms of performance, however there is a race condition on the access to r.online before the access to r.stream which may be made nil by messenger routine closing.\nTo test this, I ran a benchmark, sending 5000 messages each in their own go routine and waiting until all responses were dispatched before computing the throughput. The iorder mode is to prove that even when in async if the messages are sent one at a time (e.g. not in a go routine) the order is preserved.\nAt first, I thought the size of the message buffer might be causing the bottleneck (hence the x-axis). The buffer prevents back-pressure from the message sender, and it does appear to have some influence on sync and async mode (but less of an impact in iorder mode). From these numbers, however, it’s clear that we need to run the listener in its own routine.\nNotes:\nWith sender and receiver go routines, the message order is preserved There is a race condition between sender and receiver Buffer size only has a small impact ","wordCount":"584","inLanguage":"en","image":"https://bbengfort.github.io/bear.png","datePublished":"2018-09-11T15:19:17Z","dateModified":"2018-09-11T15:19:17Z","author":{"@type":"Person","name":"Benjamin Bengfort"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bbengfort.github.io/2018/09/streaming-remote-throughput/"},"publisher":{"@type":"Organization","name":"Libelli","logo":{"@type":"ImageObject","url":"https://bbengfort.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://bbengfort.github.io/ accesskey=h title="Libelli (Alt + H)"><img src=https://bbengfort.github.io/icon.png alt aria-label=logo height=35>Libelli</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://bbengfort.github.io/archive/ title=archive><span>archive</span></a></li><li><a href=https://bbengfort.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://bbengfort.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://bbengfort.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://bbengfort.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://bbengfort.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Streaming Remote Throughput</h1><div class=post-meta><span title='2018-09-11 15:19:17 +0000 UTC'>September 11, 2018</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;584 words&nbsp;·&nbsp;Benjamin Bengfort&nbsp;|&nbsp;<a href=https://github.com/bbengfort/bbengfort.github.io/tree/main/content/posts/2018-09-11-streaming-remote-throughput.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>In order to improve the performance of asynchronous message passing in Alia, I&rsquo;m using gRPC bidirectional streaming to create the peer to peer connections. When the replica is initialized it creates a remote connection to each of its peers that lives in its own go routine; any other thread can send messages by passing them to that go routine through a channel, replies are then dispatched via another channel, directed to the thread via an actor dispatching model.</p><p>This post is about the performance of the remote sending go routine, particularly with respect to how many threads that routine is. Here is some basic stub code for the <code>messenger</code> go routine that listens for incoming messages on a buffered channel, and sends them to the remote via the stream:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>r</span> <span class=o>*</span><span class=nx>Remote</span><span class=p>)</span> <span class=nf>messenger</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=c1>// Attempt to establish a connection to the remote peer
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=kd>var</span> <span class=nx>err</span> <span class=kt>error</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=nx>err</span> <span class=p>=</span> <span class=nx>r</span><span class=p>.</span><span class=nf>connect</span><span class=p>();</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=nx>out</span><span class=p>.</span><span class=nf>Warn</span><span class=p>(</span><span class=nx>err</span><span class=p>.</span><span class=nf>Error</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1>// Send all messages in the order they arrive on the channel
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=k>for</span> <span class=nx>msg</span> <span class=o>:=</span> <span class=k>range</span> <span class=nx>r</span><span class=p>.</span><span class=nx>messages</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=c1>// If we&#39;re not online try to re-establish the connection
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>if</span> <span class=p>!</span><span class=nx>r</span><span class=p>.</span><span class=nx>online</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nx>err</span> <span class=p>=</span> <span class=nx>r</span><span class=p>.</span><span class=nf>connect</span><span class=p>();</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=nx>out</span><span class=p>.</span><span class=nf>Warn</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=s>&#34;dropped %s message to %s (%s): could not connect&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=nx>msg</span><span class=p>.</span><span class=nx>Type</span><span class=p>,</span> <span class=nx>r</span><span class=p>.</span><span class=nx>Name</span><span class=p>,</span> <span class=nx>r</span><span class=p>.</span><span class=nf>Endpoint</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=c1>// close the connection and go to the next message
</span></span></span><span class=line><span class=cl><span class=c1></span>                <span class=nx>r</span><span class=p>.</span><span class=nb>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>// Send the message on the remote stream
</span></span></span><span class=line><span class=cl><span class=c1></span>        <span class=k>if</span> <span class=nx>err</span> <span class=p>=</span> <span class=nx>r</span><span class=p>.</span><span class=nx>stream</span><span class=p>.</span><span class=nf>Send</span><span class=p>(</span><span class=nx>msg</span><span class=p>);</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nx>out</span><span class=p>.</span><span class=nf>Warn</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=s>&#34;dropped %s message to %s (%s): could not send: %s&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=nx>msg</span><span class=p>.</span><span class=nx>Type</span><span class=p>,</span> <span class=nx>r</span><span class=p>.</span><span class=nx>Name</span><span class=p>,</span> <span class=nx>r</span><span class=p>.</span><span class=nf>Endpoint</span><span class=p>(),</span> <span class=nx>err</span><span class=p>.</span><span class=nf>Error</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1>// go offline if there was an error sending a message
</span></span></span><span class=line><span class=cl><span class=c1></span>            <span class=nx>r</span><span class=p>.</span><span class=nb>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>// But now how do we receive the reply?
</span></span></span><span class=line><span class=cl><span class=c1></span>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>The question is, how do we receive the reply from the remote?</p><p>In <strong>sync</strong> mode, we can simply receive the reply before we send the next message. This has the benefit of ensuring that there is no further synchronization required on connect and close, however as shown in the graph below, it does not perform well at all.</p><p>In <strong>async</strong> mode, we can launch another go routine to handle all the incoming requests and dispatch them:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=p>(</span><span class=nx>r</span> <span class=o>*</span><span class=nx>Remote</span><span class=p>)</span> <span class=nf>listener</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nx>r</span><span class=p>.</span><span class=nx>online</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=kd>var</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=nx>err</span> <span class=kt>error</span>
</span></span><span class=line><span class=cl>                <span class=nx>rep</span> <span class=o>*</span><span class=nx>pb</span><span class=p>.</span><span class=nx>PeerReply</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nx>rep</span><span class=p>,</span> <span class=nx>err</span> <span class=p>=</span> <span class=nx>r</span><span class=p>.</span><span class=nx>stream</span><span class=p>.</span><span class=nf>Recv</span><span class=p>();</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=nx>out</span><span class=p>.</span><span class=nf>Warn</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=s>&#34;no response from %s (%s): %s&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=nx>r</span><span class=p>.</span><span class=nx>Name</span><span class=p>,</span> <span class=nx>r</span><span class=p>.</span><span class=nf>Endpoint</span><span class=p>(),</span> <span class=nx>err</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=nx>r</span><span class=p>.</span><span class=nx>Dispatcher</span><span class=p>.</span><span class=nf>Dispatch</span><span class=p>(</span><span class=nx>events</span><span class=p>.</span><span class=nf>New</span><span class=p>(</span><span class=nx>rep</span><span class=p>.</span><span class=nf>EventType</span><span class=p>(),</span> <span class=nx>r</span><span class=p>,</span> <span class=nx>rep</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This does much better in terms of performance, however there is a race condition on the access to <code>r.online</code> before the access to <code>r.stream</code> which may be made nil by <code>messenger</code> routine closing.</p><p>To test this, I ran a benchmark, sending 5000 messages each in their own go routine and waiting until all responses were dispatched before computing the throughput. The <em>iorder</em> mode is to prove that even when in <code>async</code> if the messages are sent one at a time (e.g. not in a go routine) the order is preserved.</p><p><img loading=lazy src=/images/2018-09-11-streaming-remote-throughput.png alt=Throughput></p><p>At first, I thought the size of the message buffer might be causing the bottleneck (hence the x-axis). The buffer prevents back-pressure from the message sender, and it does appear to have some influence on sync and async mode (but less of an impact in iorder mode). From these numbers, however, it&rsquo;s clear that we need to run the listener in its own routine.</p><p>Notes:</p><ul><li>With sender and receiver go routines, the message order is preserved</li><li>There is a race condition between sender and receiver</li><li>Buffer size only has a small impact</li></ul></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://bbengfort.github.io/2018/09/go-testing-notes/><span class=title>« Prev</span><br><span>Go Testing Notes</span>
</a><a class=next href=https://bbengfort.github.io/2018/09/future-date/><span class=title>Next »</span><br><span>Future Date Script</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://bbengfort.github.io/>Libelli</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>