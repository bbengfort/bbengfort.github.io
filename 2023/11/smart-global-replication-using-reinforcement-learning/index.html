<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Smart Global Replication Using Reinforcement Learning | Libelli</title>
<meta name=keywords content><meta name=description content="Smart Global Replication using Reinforcement Learning is a talk that I gave at KubeCon + CloudNative North America 2023 in Chicago, IL. The video of the talk is below:


    
    
      
    

Description
There are many great reasons to replicate data across Kubernetes clusters in different geographic regions: e.g. for disaster recovery and to ensure the best possible user experiences. Unfortunately, global replication is not easy; not just because of the difficulty in consistency reasoning that it introduces, but also due to the increased cost of provisioning multiple volumes that exponentially duplicate ingress and egress. Wouldn&rsquo;t it be great if our systems could learn the optimal placement of storage blocks so that total replication was not necessary? Wouldn&rsquo;t it be even better if our replication messaging was reduced ensuring communication only between the minimally necessary set of storage nodes? We show a system that uses multi-armed bandits to perform such an optimization; dynamically adjusting how data is replicated based on usage. We demonstrate the savings achieved and system performance using a real world system: the TRISA Global Travel Rule Compliance Directory."><meta name=author content="Benjamin Bengfort"><link rel=canonical href=https://bbengfort.github.io/2023/11/smart-global-replication-using-reinforcement-learning/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://bbengfort.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bbengfort.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://bbengfort.github.io/icon.png><link rel=apple-touch-icon href=https://bbengfort.github.io/apple-touch-icon-precomposed.png><link rel=mask-icon href=https://bbengfort.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://bbengfort.github.io/2023/11/smart-global-replication-using-reinforcement-learning/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-D3BE7EHHVP"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D3BE7EHHVP")}</script><meta property="og:title" content="Smart Global Replication Using Reinforcement Learning"><meta property="og:description" content="Smart Global Replication using Reinforcement Learning is a talk that I gave at KubeCon + CloudNative North America 2023 in Chicago, IL. The video of the talk is below:


    
    
      
    

Description
There are many great reasons to replicate data across Kubernetes clusters in different geographic regions: e.g. for disaster recovery and to ensure the best possible user experiences. Unfortunately, global replication is not easy; not just because of the difficulty in consistency reasoning that it introduces, but also due to the increased cost of provisioning multiple volumes that exponentially duplicate ingress and egress. Wouldn&rsquo;t it be great if our systems could learn the optimal placement of storage blocks so that total replication was not necessary? Wouldn&rsquo;t it be even better if our replication messaging was reduced ensuring communication only between the minimally necessary set of storage nodes? We show a system that uses multi-armed bandits to perform such an optimization; dynamically adjusting how data is replicated based on usage. We demonstrate the savings achieved and system performance using a real world system: the TRISA Global Travel Rule Compliance Directory."><meta property="og:type" content="article"><meta property="og:url" content="https://bbengfort.github.io/2023/11/smart-global-replication-using-reinforcement-learning/"><meta property="og:image" content="https://bbengfort.github.io/bear.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-11-07T12:00:00-05:00"><meta property="article:modified_time" content="2023-11-07T12:00:00-05:00"><meta property="og:site_name" content="Libelli"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bbengfort.github.io/bear.png"><meta name=twitter:title content="Smart Global Replication Using Reinforcement Learning"><meta name=twitter:description content="Smart Global Replication using Reinforcement Learning is a talk that I gave at KubeCon + CloudNative North America 2023 in Chicago, IL. The video of the talk is below:


    
    
      
    

Description
There are many great reasons to replicate data across Kubernetes clusters in different geographic regions: e.g. for disaster recovery and to ensure the best possible user experiences. Unfortunately, global replication is not easy; not just because of the difficulty in consistency reasoning that it introduces, but also due to the increased cost of provisioning multiple volumes that exponentially duplicate ingress and egress. Wouldn&rsquo;t it be great if our systems could learn the optimal placement of storage blocks so that total replication was not necessary? Wouldn&rsquo;t it be even better if our replication messaging was reduced ensuring communication only between the minimally necessary set of storage nodes? We show a system that uses multi-armed bandits to perform such an optimization; dynamically adjusting how data is replicated based on usage. We demonstrate the savings achieved and system performance using a real world system: the TRISA Global Travel Rule Compliance Directory."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://bbengfort.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Smart Global Replication Using Reinforcement Learning","item":"https://bbengfort.github.io/2023/11/smart-global-replication-using-reinforcement-learning/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Smart Global Replication Using Reinforcement Learning","name":"Smart Global Replication Using Reinforcement Learning","description":"Smart Global Replication using Reinforcement Learning is a talk that I gave at KubeCon + CloudNative North America 2023 in Chicago, IL. The video of the talk is below:\nDescription There are many great reasons to replicate data across Kubernetes clusters in different geographic regions: e.g. for disaster recovery and to ensure the best possible user experiences. Unfortunately, global replication is not easy; not just because of the difficulty in consistency reasoning that it introduces, but also due to the increased cost of provisioning multiple volumes that exponentially duplicate ingress and egress. Wouldn\u0026rsquo;t it be great if our systems could learn the optimal placement of storage blocks so that total replication was not necessary? Wouldn\u0026rsquo;t it be even better if our replication messaging was reduced ensuring communication only between the minimally necessary set of storage nodes? We show a system that uses multi-armed bandits to perform such an optimization; dynamically adjusting how data is replicated based on usage. We demonstrate the savings achieved and system performance using a real world system: the TRISA Global Travel Rule Compliance Directory.\n","keywords":[],"articleBody":"Smart Global Replication using Reinforcement Learning is a talk that I gave at KubeCon + CloudNative North America 2023 in Chicago, IL. The video of the talk is below:\nDescription There are many great reasons to replicate data across Kubernetes clusters in different geographic regions: e.g. for disaster recovery and to ensure the best possible user experiences. Unfortunately, global replication is not easy; not just because of the difficulty in consistency reasoning that it introduces, but also due to the increased cost of provisioning multiple volumes that exponentially duplicate ingress and egress. Wouldn’t it be great if our systems could learn the optimal placement of storage blocks so that total replication was not necessary? Wouldn’t it be even better if our replication messaging was reduced ensuring communication only between the minimally necessary set of storage nodes? We show a system that uses multi-armed bandits to perform such an optimization; dynamically adjusting how data is replicated based on usage. We demonstrate the savings achieved and system performance using a real world system: the TRISA Global Travel Rule Compliance Directory.\n","wordCount":"178","inLanguage":"en","image":"https://bbengfort.github.io/bear.png","datePublished":"2023-11-07T12:00:00-05:00","dateModified":"2023-11-07T12:00:00-05:00","author":{"@type":"Person","name":"Benjamin Bengfort"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bbengfort.github.io/2023/11/smart-global-replication-using-reinforcement-learning/"},"publisher":{"@type":"Organization","name":"Libelli","logo":{"@type":"ImageObject","url":"https://bbengfort.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://bbengfort.github.io/ accesskey=h title="Libelli (Alt + H)"><img src=https://bbengfort.github.io/icon.png alt aria-label=logo height=35>Libelli</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://bbengfort.github.io/archive/ title=archive><span>archive</span></a></li><li><a href=https://bbengfort.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://bbengfort.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://bbengfort.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://bbengfort.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://bbengfort.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Smart Global Replication Using Reinforcement Learning</h1><div class=post-meta><span title='2023-11-07 12:00:00 -0500 -0500'>November 7, 2023</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;178 words&nbsp;·&nbsp;Benjamin Bengfort&nbsp;|&nbsp;<a href=https://github.com/bbengfort/bbengfort.github.io/tree/main/content/posts/2023-11-07-smart-global-replication-using-reinforcement-learning.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p><a href=https://kccncna2023.sched.com/event/21d4640540a0961019d201de8ec2fd5e>Smart Global Replication using Reinforcement Learning</a> is a talk that I gave at KubeCon + CloudNative North America 2023 in Chicago, IL. The video of the talk is below:</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/YTF2dXNhFzI?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><h3 id=description>Description<a hidden class=anchor aria-hidden=true href=#description>#</a></h3><p>There are many great reasons to replicate data across Kubernetes clusters in different geographic regions: e.g. for disaster recovery and to ensure the best possible user experiences. Unfortunately, global replication is not easy; not just because of the difficulty in consistency reasoning that it introduces, but also due to the increased cost of provisioning multiple volumes that exponentially duplicate ingress and egress. Wouldn&rsquo;t it be great if our systems could learn the optimal placement of storage blocks so that total replication was not necessary? Wouldn&rsquo;t it be even better if our replication messaging was reduced ensuring communication only between the minimally necessary set of storage nodes? We show a system that uses multi-armed bandits to perform such an optimization; dynamically adjusting how data is replicated based on usage. We demonstrate the savings achieved and system performance using a real world system: the TRISA Global Travel Rule Compliance Directory.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://bbengfort.github.io/2023/08/diy-consensus-crafting-your-own-distributed-code/><span class=title>Next »</span><br><span>DIY Consensus: Crafting Your Own Distributed Code (with Benjamin Bengfort)</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://bbengfort.github.io/>Libelli</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>