<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Anonymizing User Profile Data with Faker | Libelli</title><meta name=keywords content><meta name=description content="This post is an early draft of expanded work that will eventually appear on the District Data Labs Blog. Your feedback is welcome, and you can submit your comments on the draft GitHub issue.
 In order to learn (or teach) data science you need data (surprise!). The best libraries often come with a toy dataset to show examples and how the code works. However, nothing can replace an actual, non-trivial dataset for a tutorial or lesson because it provides for deep and meaningful further exploration."><meta name=author content="Benjamin Bengfort"><link rel=canonical href=https://bbengfort.github.io/2016/02/anonymizing-profile-data/><link crossorigin=anonymous href=/assets/css/stylesheet.min.d0c0348c2d0cff14148d0e347258519d8df2ce53ce5ac32c7bd9a549182cb8ae.css integrity="sha256-0MA0jC0M/xQUjQ40clhRnY3yzlPOWsMse9mlSRgsuK4=" rel="preload stylesheet" as=style><link rel=preload href=/icon.png as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=https://bbengfort.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bbengfort.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://bbengfort.github.io/icon.png><link rel=apple-touch-icon href=https://bbengfort.github.io/apple-touch-icon-precomposed.png><link rel=mask-icon href=https://bbengfort.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.79.0"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-8096804-11','auto');ga('send','pageview');}</script><meta property="og:title" content="Anonymizing User Profile Data with Faker"><meta property="og:description" content="This post is an early draft of expanded work that will eventually appear on the District Data Labs Blog. Your feedback is welcome, and you can submit your comments on the draft GitHub issue.
 In order to learn (or teach) data science you need data (surprise!). The best libraries often come with a toy dataset to show examples and how the code works. However, nothing can replace an actual, non-trivial dataset for a tutorial or lesson because it provides for deep and meaningful further exploration."><meta property="og:type" content="article"><meta property="og:url" content="https://bbengfort.github.io/2016/02/anonymizing-profile-data/"><meta property="og:image" content="https://bbengfort.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2016-02-25T12:32:54+00:00"><meta property="article:modified_time" content="2016-02-25T12:32:54+00:00"><meta property="og:site_name" content="Libelli"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bbengfort.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Anonymizing User Profile Data with Faker"><meta name=twitter:description content="This post is an early draft of expanded work that will eventually appear on the District Data Labs Blog. Your feedback is welcome, and you can submit your comments on the draft GitHub issue.
 In order to learn (or teach) data science you need data (surprise!). The best libraries often come with a toy dataset to show examples and how the code works. However, nothing can replace an actual, non-trivial dataset for a tutorial or lesson because it provides for deep and meaningful further exploration."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://bbengfort.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Anonymizing User Profile Data with Faker","item":"https://bbengfort.github.io/2016/02/anonymizing-profile-data/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Anonymizing User Profile Data with Faker","name":"Anonymizing User Profile Data with Faker","description":"This post is an early draft of expanded work that will eventually appear on the District Data Labs Blog. Your feedback is welcome, and you can submit your comments on the draft GitHub issue.\n In order to learn (or teach) data science you need data (surprise!). The best libraries often come with a toy dataset to show examples and how the code works. However, nothing can replace an actual, non-trivial dataset for a tutorial or lesson because it provides for deep and meaningful further exploration.","keywords":[],"articleBody":" This post is an early draft of expanded work that will eventually appear on the District Data Labs Blog. Your feedback is welcome, and you can submit your comments on the draft GitHub issue.\n In order to learn (or teach) data science you need data (surprise!). The best libraries often come with a toy dataset to show examples and how the code works. However, nothing can replace an actual, non-trivial dataset for a tutorial or lesson because it provides for deep and meaningful further exploration. Non-trivial datasets can provide surprise and intuition in a way that toy datasets just cannot. Unfortunately, non-trivial datasets can be hard to find for a few reasons, but one common reason is that the dataset contains personally identifying information (PII).\nA possible solution to dealing with PII is to anonymize1the data set by replacing information that can identify a real individual with information about a fake (but similarly behaving) fake individual. Unfortunately this is not as easy at it sounds at a glance. A simple mapping of real data to randomized data is not enough because anonymization needs to preserve the semantics of the dataset in order to be used as a stand in for analytical purposes. As a result, issues related to entity resolution2like managing duplicates or producing linkable results come into play.\nThe good news is that we can take a cue from the database community, who routinely generate data sets in order to evaluate the performance of a database system. This community, especially in a web or test driven development context, has a lot of tools for generating very realistic data for a variety of information types. For this post, I’ll explore using the Faker library to generate a realistic, anonymized dataset that can be utilized for downstream analysis.\nThe goal can therefore be summarized as follows: given a target dataset (let’s say for simplicity, a CSV file with multiple columns), produce a new dataset such that for each row in the target, the anonymized dataset does not contain any personally identifying information. The anonymized dataset should have the same amount of data, as well as maintain its value for analysis.\nAnonymizing CSV Data In this example we’re going to do something very simple, we’re going to anonymize only two fields: full name and email. Sounds easy, right? The issue is that we want to preserve the semantic relationships and patterns in our target dataset so that we can hand it off to be analyzed or mined for interesting patterns. What happens if there are multiple rows per user? Since CSV data is naturally denormalized (e.g. contains redundant data like rows with repeated full names and emails) we will need to maintain a mapping of profile information.\nNote: Since we’re going to be using Python 2.7 in this example, you’ll need to install the unicodecsv module with pip. Additionally you’ll need the Faker library:\n$ pip install fake-factory unicodecsv  The following example shows a simple anonymize_rows function that maintains this mapping and also shows how to generate data with Faker. We’ll also go a step further and read the data from a source CSV file and write the anonymized data to a target CSV file. The end result is that the file should be very similar in terms of length, row order, and fields, the only difference being that names and emails have been replaced with fake names and emails.\nimport unicodecsv as csv from faker import Factory from collections import defaultdict def anonymize_rows(rows): \"\"\" Rows is an iterable of dictionaries that contain a name and email field that need to be anonymized. \"\"\" # Load the faker and its providers faker = Factory.create() # Create mappings of names \u0026 emails to faked names \u0026 emails. names = defaultdict(faker.name) emails = defaultdict(faker.email) # Iterate over the rows and yield anonymized rows. for row in rows: # Replace the name and email fields with faked fields. row['name'] = names[row['name']] row['email'] = emails[row['email']] # Yield the row back to the caller yield row def anonymize(source, target): \"\"\" source is a path to a CSV file containing data to anonymize. target is a path to write the anonymized CSV data to. \"\"\" with open(source, 'rU') as f: with open(target, 'w') as o: # Use the DictReader to easily extract fields reader = csv.DictReader(f) writer = csv.DictWriter(o, reader.fieldnames) # Read and anonymize data, writing to target file. for row in anonymize_rows(reader): writer.writerow(row) The entry point for this code is the anonymize function itself. It takes as input the path to two files: the source, where the target data is held in CSV form, and target a path to write out the anonymized data to. Both of these paths are opened for reading and writing respectively, then the unicodecsv module is used to read and parse each row, transforming them into Python dictionaries. Those dictionaries are passed into the anonymize_rows function, which transforms and yields each row to be written by the CSV writer to disk.\nThe anonymize_rows function takes any iterable of dictionaries which contain name and email keys. It loads the fake factory using Factory.create - a class function that loads various providers with methods that generate fake data (more on this later). We then create two defaultdict to map names to fake names and emails to fake emails.\nThe Python collections module provides the defaultdict which is similar to a regular dict except that if the key does not exist in the dictionary, a default value is supplied by the callable passed in at instantiation. For example, d = defaultdict(int) would provide a default value of 0 for every key not already in the dictionary. Therefore when we use defaultdict(faker.name) we’re saying that for every key not in the dictionary, create a fake name (and similar for email). This allows us to generate a mapping of real data to fake data, and make sure that the real value always maps to the same fake value.\nFrom there we simply iterate through all the rows, replacing data as necessary. If our target CSV file looked like this (imagine clickstream data from an email marketing campaign):\nname,email,value,time,ipaddr James Hinglee,jhinglee@gmail.com,a,1446288248,202.12.32.123 Nancy Smithfield,unicorns4life@yahoo.com,b,1446288250,67.212.123.201 J. Hinglee,jhinglee@gmail.com,b,1446288271,202.12.32.123 It would be transformed to something as follows:\nMr. Sharif Lehner,keion.hilll@gmail.com,a,1446288248,202.12.32.123 Webster Kulas,nienow.finnegan@gmail.com,b,1446288250,67.212.123.201 Maceo Turner MD,keion.hilll@gmail.com,b,1446288271,202.12.32.123 We now have a new wrangling tool in our toolbox that will allow us to transform CSVs with name and email fields into anonymized datasets! This naturally leads us to the question: what else can we anonymize?\nGenerating Fake Data There are two third party libraries for generating fake data with Python that come up on Google search results: Faker by @deepthawtz and Fake Factory by @joke2k, which is also called “Faker”. Faker provides anonymization for user profile data, which is completely generated on a per-instance basis. Fake Factory (used in the example above) uses a providers approach to load many different fake data generators in multiple languages. Because Fake Factory has multiple language support, and a wider array of fake data generators, I typically use it over the more intuitive and simple to use Faker library which only does fake user profiles and we’ll inspect it in detail for the rest of this post (everywhere except in this paragraph, when I refer to Faker, I’m referring to Fake Factory).\nThe primary interface that Faker provides is called a Generator. Generators are a collection of Provider instances which are responsible for formatting random data for a particular domain. Generators also provide a wrapper around the random module, and allow you to set the random seed and other operations. While you could theoretically instantiate your own Generator with your own providers, Faker provides a Factory to automatically load all the providers on your behalf:\n from faker import Factory  fake = Factory.create() If you inspect the fake object, you’ll see around 158 methods (at the time of this writing) that all generate fake data. Please allow me to highlight a few:\n fake.credit_card_number() u'180029425031151'  fake.military_ship() u'USCGC'  (fake.latitude(), fake.longitude()) (Decimal('-39.4682475'), Decimal('50.449170'))  fake.hex_color() u'#559135'  fake.pyset(3) set([u'Et possimus.', u'Blanditiis vero.', u'Ad odio ad qui.', 9855]) Importantly, providers can also be localized using a language code; and this is probably the best reason to use the Factory object — to ensure that localized providers, or subsets of providers are loaded correctly. For example, to load the French localization:\n fake = Factory.create('fr_FR')  fake.catch_phrase_verb() u\"d'atteindre vos buts\" And for fun, some Chinese:\n fake = Factory.create('cn_ZH')  print fake.company() u\"快讯科技有限公司\" As you can see there are a wide variety of tools and techniques to generate fake data from a variety of domains. The best way to explore all the providers in detail is simply to look at the providers package on GitHub.\nCreating A Provider Although the Faker library has a very comprehensive array of providers, occasionally you need a domain specific fake data generator. In order to add a custom provider, you will need to subclass the BaseProvider and expose custom fake methods as class methods using the @classmethod decorator. One very easy approach is to create a set of random data you’d like to expose, and simply randomly select it:\nfrom faker.providers import BaseProvider class OceanProvider(BaseProvider): __provider__ = \"ocean\" __lang__ = \"en_US\" oceans = [ u'Atlantic', u'Pacific', u'Indian', u'Arctic', u'Southern', ] @classmethod def ocean(cls): return cls.random_element(cls.oceans) In order to change the likelihood or distribution of which oceans are selected, simply add duplicates to the oceans list so that each name has the probability of selection that you’d like. Then add your provider to the Faker object:\n fake = Factory.create()  fake.add_provider(OceanProvider)  fake.ocean() u'Indian' In routine data wrangling operations, you may create a package structure with localization similar to how Faker is organized and load things on demand. Don’t forget — if you come up with a generic provider that may be useful to many people, submit it back as a pull request!\nMaintaining Data Quality Now that we understand the wide variety of fake data we can generate, let’s get back to our original example of creating user profile data of just name and email address. First, if you look at the results in the section above, we can make a few observations:\n Pro: exact duplicates of name and email are maintained via the mapping. Pro: our user profiles are now fake data and PII is protected. Con: the name and the email are weird and don’t match. Con: fuzzy duplicates (e.g. J. Smith vs. John Smith) are blown away. Con: all the domains are “free email” like Yahoo and Gmail.  Basically we want to improve our user profile to include email addresses that are similar to the names (or a non-name based username), and we want to ensure that the domains are a bit more realistic for work addresses. We also want to include aliases, nicknames, or different versions of the name. Faker does provide a profile provider:\n fake.simple_profile() u'{ \"username\": \"autumn.weissnat\", \"name\": \"Jalyn Crona\", \"birthdate\": \"1981-01-29\", \"sex\": \"F\", \"address\": \"Unit 2875 Box 1477\\nDPO AE 18742-1954\", \"mail\": \"zollie.schamberger@hotmail.com\" }' But as you can see, it suffers from the same problem. In this section, we’ll explore different techniques that allow us to pass over the data and modify our fake data generation such that it matches the distributions we’re seeing in the original data set. In particular we’ll deal with the domain, creating more realistic fake profiles, and adding duplicates to our data set with fuzzy matching.\nDomain Distribution One idea to maintain the distribution of domains is to do a first pass over the data and create a mapping of real domain to fake domain. Moreover, many domains like gmail.com can be whitelisted and mapped directly to itself (we just need a fake username). Additionally, we can also preserve capitalization and spelling via this method, e.g. “Gmail.com” and “GMAIL.com” which might be important for data sets that have been entered by hand.\nIn order to create the domain mapping/whitelist, we’ll need to create an object that can load a whitelist from disk, or generate one from our original dataset. I propose the following utility:\nimport csv import json from faker import Factory from collections import Counter from collections import MutableMapping class DomainMapping(MutableMapping): @classmethod def load(cls, fobj): \"\"\" Load the mapping from a JSON file on disk. \"\"\" data = json.load(fobj) return cls(**data) @classmethod def generate(cls, emails): \"\"\" Pass through a list of emails and count domains to whitelist. \"\"\" # Count all the domains in each email address counts = Counter([ email.split(\"@\")[-1] for email in emails ]) # Create a domain mapping domains = cls() # Ask the user what domains to whitelist based on frequency for idx, (domain, count) in enumerate(counts.most_common())): prompt = \"{}/{}: Whitelist {} ({} addresses)?\".format( idx+1, len(counts), domain, count ) print prompt ans = raw_input(\"[y/n/q]  \").lower() if ans.startswith('y'): # Whitelist the domain domains[domain] = domain elif ans.startswith('n'): # Create a fake domain domains[domain] elif ans.startswith('q'): break else: continue return domains def __init__(self, whitelist=[], mapping={}): # Create the domain mapping properties self.fake = Factory.create() self.domains = mapping # Add the whitelist as a mapping to itself. for domain in whitelist: self.domains[domain] = domain def dump(self, fobj): \"\"\" Dump the domain mapping whitelist/mapping to JSON. \"\"\" whitelist = [] mapping = self.domains.copy() for key in mapping.keys(): if key == mapping[key]: whitelist.append(mapping.pop(key)) json.dump({ 'whitelist': whitelist, 'mapping': mapping }, fobj, indent=2) def __getitem__(self, key): \"\"\" Get a fake domain for a real domain. \"\"\" if key not in self.domains: self.domains[key] = self.fake.domain_name() return self.domains[key] def __setitem__(self, key, val): self.domains[key] = val def __delitem__(self, key): del self.domains[key] def __iter__(self): for key in self.domains: yield key Right so that’s quite a lot of code all at once, so let’s break it down a bit. First, the class extends MutableMapping which is an abstract base class in the collections module. The ABC gives us the ability to make this class act just like a dict object. All we have to do is provide __getitem__, __setitem__, __delitem__, and __iter__ methods and all other dictionary methods like pop, or values work on our behalf. Here, we’re just wrapping an inner dictionary called domains.\nThe thing to note about our __getitem__ method is that it acts very similar to a defaultdict, that is if you try to fetch a key that is not in the mapping, then it generates fake data on your behalf. This way, any domains that we don’t have in our whitelist or mapping will automatically be anonymized.\nNext, we want to be able to load and dump this data to a JSON file on disk, that way we can maintain our mapping between anonymization runs. The load method is fairly straight forward, it just takes an open file-like object and parses it uses the json module, and instantiates the domain mapping and returns it. The dump method is a bit more complex, it has to break down the whitelist and mapping into separate objects, so that we can easily modify the data on disk if needed. Together, these methods will allow you to load and save your mapping into a JSON file that will look similar to:\n{ \"whitelist\": [ \"gmail.com\", \"yahoo.com\" ], \"mapping\": { \"districtdatalabs.com\": \"fadel.org\", \"umd.edu\": \"ferrystanton.org\" } } The final method of note is the generate method. The generate method allows you to do a first pass through a list of emails, count the frequency of the domains, then propose to the user in order of most frequent domain whether or not to add it to the whitelist. For each domain in the emails, the user is prompted as follows:\n1/245: Whitelist \"gmail.com\" (817 addresses)? [y/n/q]  Note that the prompt includes a progress indicator (this is prompt 1 of 245) as well as a method to quit early. This is especially important for large datasets that have a lot of single domains; if you quit, the domains will still be faked, and the user only sees the most frequent examples for whitelisting. The idea behind this mechanism to read through your CSV once, generate the whitelist, then save it to disk so that you can use it for anonymization on a routine basis. Moreover, you can modify domains in the JSON file to better match any semantics you might have (e.g. include .edu or .gov domains, which are not generated by the internet provider in Faker).\nRealistic Profiles To create realistic profiles, we’ll create a provider that uses the domain map from above and generates fake data for every combination we see in the data set. This provider will also provide opportunities for mapping multiple names and email addresses to a single profile so that we can use the profile for creating fuzzy duplicates in the next section. Here is the code:\nclass Profile(object): def __init__(self, domains): self.domains = domains self.generator = Factory.create() def fuzzy_profile(self, name=None, email=None): \"\"\" Return an profile that allows for fuzzy names and emails. \"\"\" parts = self.fuzzy_name_parts() return { \"names\": {name: self.fuzzy_name(parts, name)}, \"emails\": {email: self.fuzzy_email(parts, email)}, } def fuzzy_name_parts(self): \"\"\" Returns first, middle, and last name parts \"\"\" return ( self.generator.first_name(), self.generator.first_name(), self.generator.last_name() ) def fuzzy_name(self, parts, name=None): \"\"\" Creates a name that has similar case to the passed in name. \"\"\" # Extract the first, initial, and last name from the parts. first, middle, last = parts # Create the name, with chance of middle or initial included. chance = self.generator.random_digit() if chance  2: fname = u\"{} {}. {}\".format(first, middle[0], last) elif chance  4: fname = u\"{} {} {}\".format(first, middle, last) else: fname = u\"{} {}\".format(first, last) if name is not None: # Match the capitalization of the name if name.isupper(): return fname.upper() if name.islower(): return fname.lower() return fname def fuzzy_email(self, parts, email=None): \"\"\" Creates an email similar to the name and original email. \"\"\" # Extract the first, initial, and last name from the parts. first, middle, last = parts # Use the domain mapping to identify the fake domain. if email is not None: domain = self.domains[email.split(\"@\")[-1]] else: domain = self.generator.domain_name() # Create the username based on the name parts chance = self.generator.random_digit() if chance  2: username = u\"{}.{}\".format(first, last) elif chance  3: username = u\"{}.{}.{}\".format(first, middle[0], last) elif chance  6: username = u\"{}{}\".format(first[0], last) elif chance  8: username = last else: username = u\"{}{}\".format( first, self.generator.random_number() ) # Match the case of the email if email is not None: if email.islower(): username = username.lower() if email.isupper(): username = username.upper() else: username = username.lower() return u\"{}@{}\".format(username, domain) Again, this is a lot of code, make sure you go through it carefully so you understand what is happening. First off, a profile in this case is the combination of a mapping of names to fake names and emails to fake emails. The key is that the names and emails are related to original data somehow. In this case, the relationship is through case such that “DANIEL WEBSTER” is faked to “JAKOB WILCOTT” instead of to “Jakob Wilcott”. Additionally through our domain mapping, we also maintain the relationship of the original email domain to the fake domain mapping, e.g. everyone with the an email domain “@districtdatalabs.com” will be mapped to the same fake domain.\nIn order to maintain the relationship of names to emails (which is very common), we need to be able to access the name more directly. In this case we have a name parts generator which generates fake first, middle, and last names. We then randomly generate names of the form “first last”, “first middle last”, or “first i. last” with random chance. Additionally the email can take a variety of forms based on the name parts as well. Now we get slightly more realistic profiles:\n fake.fuzzy_profile() {'names': {None: u'Zaire Ebert'}, 'emails': {None: u'ebert@von.com'}}  fake.fuzzy_profile( ... name='Daniel Webster', email='dictionaryguy@gmail.com') {'names': {'Daniel Webster': u'Georgia McDermott'}, 'emails': {'dictionaryguy@gmail.com': u'georgia9@gmail.com'}} Importantly this profile object makes it easy to map multiple names and emails to the same profile object to create “fuzzy” profiles and duplicates in your dataset. We will discuss how to perform fuzzy matching in the next section.\nFuzzing Fake Names from Duplicates If you noticed in our original data set we had the situation where we had a clear entity duplication: same email, but different names. In fact, the second name was simply the first initial and last name but you could imagine other situations like nicknames (“Bill” instead of “William”), or having both work and personal emails in the dataset. The fuzzy profile objects we generated in the last section allow us to maintain a mapping of all name parts to generated fake names, but we need some way to be able to detect duplicates and combine their profile: enter the fuzzywuzzy module.\n$ pip install fuzzywuzzy python-Levenshtein  Similar to how we did the domain mapping, we’re going to pass through the entire dataset and look for similar name, email pairs and propose them to the user. If the user thinks they’re duplicates, then we’ll merge them together into a single profile, and use the mappings as we anonymize. Although I won’t go through an entire object to do this as with the domain map, this is also something you can save to disk and load on demand for multiple anonymization passes and to include user based edits.\nThe first step is to get pairs, and eliminate exact duplicates. To do this we’ll create a hashable data structure for our profiles using a namedtuple.\nfrom collections import namedtuple from itertools import combinations Person = namedtuple('Person', 'name, email') def pairs_from_rows(rows): \"\"\" Expects rows of dictionaries with name and email keys. \"\"\" # Create a set of person tuples (no exact duplicates) people = set([ Person(row['name'], row['email']) for row in rows ]) # Yield ordered pairs of people objects without replacement for pair in combinations(people, 2): yield pair The namedtuple is an immutable data structure that is compact, efficient, and allows us to access properties by name. Because it is immutable it is also hashable (unlike mutable dictionaries), meaning we can use it as keys in sets and dictionaries. This is important, because the first thing our pairs_from_rows function does is eliminate exact matches by creating a set of Person tuples. We then use the combinations function in itertools to generate every pair without replacement.\nThe next step is to figure out how similar each pair is. To do this we’ll use the fuzzywuzzy library to come up with a partial ratio score: the mean of the similarity of the names and the emails for each pair:\nfrom fuzzywuzzy import fuzz from functools import partial def normalize(value, email=False): \"\"\" Make everything lowercase and remove spaces. If email, only take the username portion to compare. \"\"\" if email: value = value.split(\"@\")[0] return value.lower().replace(\" \", \"\") def person_similarity(pair): \"\"\" Returns the mean of the normalized partial ratio scores. \"\"\" # Normalize the names and the emails names = map(normalize, [p.name for p in pair]) email = map( partial(normalize, email=True), [p.email for p in pair] ) # Compute the partial ratio scores for both names and emails scores = [ fuzz.partial_ratio(a, b) for a, b in [names, emails] ] # Return the mean score of the pair return float(sum(scores)) / len(scores) The score will be between 0 (no similarity) and 100 (exact match), though hopefully you won’t get any scores of 100 since we eliminated exact matches above. For example:\n person_similarity([ ... Person('John Lennon', 'john.lennon@gmail.com'), ... Person('J. Lennon', 'jlennon@example.org') ... ]) 80.5 The fuzzing process will go through your entire dataset, and create pairs of people it finds and compute their similarity score. Filter all pairs except for scores that meet a threshold (say, 50) then propose them to the user to decide if they’re duplicates in descending score order. When a duplicate is found, merge the profile object to map the new names and emails together.\nConclusion Anonymization of datasets is a critical method to promote the exploration and practice of data science through open data. Fake data generators that already exist give us the opportunity to ensure that private data is obfuscated. This issue becomes how to leverage these fake data generators while still maintaining a high quality dataset with semantic relations preserved for further analysis. As we’ve seen throughout the post, even just the anonymization of just two fields, name and email can lead to potential problems.\nThis problem, and the code in this post are associated with a real case study. For District Data Labs' Entity Resolution Research Lab3I wanted to create a dataset that removed PII of DDL members while maintaining duplicates and structure to study entity resolution. The source dataset was 1,343 records in CSV form and contained name and emails that I wanted to anonymize.\nUsing the strategy I mentioned for domain name mapping, the dataset contained 245 distinct domain names, 185 of which were hapax legomena (appeared only once). There was a definite long tail, as the first 20 or so most frequent domains were the majority of the records. Once I generated the whitelist as above, I manually edited the mappings to ensure that there were no duplicates and that major work domains were “professional enough”.\nUsing the fuzzy matching process was also a bear. It took on average, 28 seconds to compute the pairwise scores. Using a threshold score of 50, I was proposed 5,110 duplicates (out of a possible 901,153 combinations). I went through 354 entries (until the score was below 65) and was satisfied that I covered many of the duplicates in the dataset.\nIn the end the dataset that I anonymized was of a high quality. It obfuscated personally identifying information like name and email and I’m happy to make the data set public. Of course, you could reverse the some of the information in the dataset. For example, I’m listed in the dataset, and one of the records indicates a relationship between a fake user and a blog post, which I’m on record as having written. However, even though you can figure out who I am and what else I’ve done in the dataset, you wouldn’t be able to use it to extract my email address, which was the goal.\nIn the end, anonymizing a dataset is a lot of work, with a lot of gotchas and hoops to jump through. However, I hope you will agree that it is invaluable in an open data context. By sharing data, resources, and tools we can use many eyes to provide multiple insights and to drive data science forward.\nFootnotes 1.Anonymize: remove identifying particulars from (test results) for statistical or other purposes.\n2.Entity Resolution: tools or techniques that identify, group, and link digital mentions or manifestations of some object in the real world.\n3.DDL Research Labs is an applied research program intended to develop novel, innovative data science solutions towards practical applications.\n","wordCount":"4460","inLanguage":"en","datePublished":"2016-02-25T12:32:54Z","dateModified":"2016-02-25T12:32:54Z","author":{"@type":"Person","name":"Benjamin Bengfort"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bbengfort.github.io/2016/02/anonymizing-profile-data/"},"publisher":{"@type":"Organization","name":"Libelli","logo":{"@type":"ImageObject","url":"https://bbengfort.github.io/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: #1d1e20;--entry: #2e2e33;--primary: rgba(255, 255, 255, 0.84);--secondary: rgba(255, 255, 255, 0.56);--tertiary: rgba(255, 255, 255, 0.16);--content: rgba(255, 255, 255, 0.74);--hljs-bg: #2e2e33;--code-bg: #37383e;--border: #333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://bbengfort.github.io accesskey=h title="Libelli (Alt + H)"><img src=/icon.png alt=logo aria-label=logo height=35>Libelli</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://bbengfort.github.io/archive/ title=archive><span>archive</span></a></li><li><a href=https://bbengfort.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://bbengfort.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://bbengfort.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Anonymizing User Profile Data with Faker</h1><div class=post-meta>February 25, 2016&nbsp;·&nbsp;21 min&nbsp;·&nbsp;Benjamin Bengfort</div></header><div class=post-content><blockquote><p>This post is an early draft of expanded work that will eventually appear on the <a href=http://blog.districtdatalabs.com/>District Data Labs Blog</a>. Your feedback is welcome, and you can submit your comments on the <a href=https://github.com/bbengfort/bbengfort.github.io/issues/3>draft GitHub issue</a>.</p></blockquote><p>In order to learn (or teach) data science you need data (surprise!). The best libraries often come with a toy dataset to show examples and how the code works. However, nothing can replace an actual, non-trivial dataset for a tutorial or lesson because it provides for deep and meaningful further exploration. Non-trivial datasets can provide surprise and intuition in a way that toy datasets just cannot. Unfortunately, non-trivial datasets can be hard to find for a few reasons, but one common reason is that the dataset contains personally identifying information (PII).</p><p>A possible solution to dealing with PII is to <em>anonymize</em><a href=#apd-footnote-1>1</a> the data set by replacing information that can identify a real individual with information about a fake (but similarly behaving) fake individual. Unfortunately this is not as easy at it sounds at a glance. A simple mapping of real data to randomized data is not enough because anonymization needs to preserve the semantics of the dataset in order to be used as a stand in for analytical purposes. As a result, issues related to <em>entity resolution</em><a href=#apd-footnote-2>2</a> like managing duplicates or producing linkable results come into play.</p><p>The good news is that we can take a cue from the database community, who routinely <em>generate</em> data sets in order to evaluate the performance of a database system. This community, especially in a web or test driven development context, has a lot of tools for generating very realistic data for a variety of information types. For this post, I&rsquo;ll explore using the <a href=https://github.com/joke2k/faker>Faker</a> library to generate a realistic, anonymized dataset that can be utilized for downstream analysis.</p><p>The goal can therefore be summarized as follows: given a target dataset (let&rsquo;s say for simplicity, a CSV file with multiple columns), produce a new dataset such that for each row in the target, the anonymized dataset does not contain any personally identifying information. The anonymized dataset should have the same amount of data, as well as maintain its value for analysis.</p><h2 id=anonymizing-csv-data>Anonymizing CSV Data<a hidden class=anchor aria-hidden=true href=#anonymizing-csv-data>#</a></h2><p>In this example we&rsquo;re going to do something very simple, we&rsquo;re going to anonymize only two fields: full name and email. Sounds easy, right? The issue is that we want to preserve the semantic relationships and patterns in our target dataset so that we can hand it off to be analyzed or mined for interesting patterns. What happens if there are multiple rows per user? Since CSV data is naturally denormalized (e.g. contains redundant data like rows with repeated full names and emails) we will need to maintain a mapping of profile information.</p><p><strong>Note</strong>: Since we&rsquo;re going to be using Python 2.7 in this example, you&rsquo;ll need to install the <code>unicodecsv</code> module with <code>pip</code>. Additionally you&rsquo;ll need the Faker library:</p><pre><code>$ pip install fake-factory unicodecsv
</code></pre><p>The following example shows a simple <code>anonymize_rows</code> function that maintains this mapping and also shows how to generate data with Faker. We&rsquo;ll also go a step further and read the data from a source CSV file and write the anonymized data to a target CSV file. The end result is that the file should be very similar in terms of length, row order, and fields, the only difference being that names and emails have been replaced with fake names and emails.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> unicodecsv <span style=color:#f92672>as</span> csv
<span style=color:#f92672>from</span> faker <span style=color:#f92672>import</span> Factory
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> defaultdict

<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>anonymize_rows</span>(rows):
    <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>    Rows is an iterable of dictionaries that contain a name and
</span><span style=color:#e6db74>    email field that need to be anonymized.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    <span style=color:#75715e># Load the faker and its providers</span>
    faker  <span style=color:#f92672>=</span> Factory<span style=color:#f92672>.</span>create()

    <span style=color:#75715e># Create mappings of names &amp; emails to faked names &amp; emails.</span>
    names  <span style=color:#f92672>=</span> defaultdict(faker<span style=color:#f92672>.</span>name)
    emails <span style=color:#f92672>=</span> defaultdict(faker<span style=color:#f92672>.</span>email)

    <span style=color:#75715e># Iterate over the rows and yield anonymized rows.</span>
    <span style=color:#66d9ef>for</span> row <span style=color:#f92672>in</span> rows:
        <span style=color:#75715e># Replace the name and email fields with faked fields.</span>
        row[<span style=color:#e6db74>&#39;name&#39;</span>]  <span style=color:#f92672>=</span> names[row[<span style=color:#e6db74>&#39;name&#39;</span>]]
        row[<span style=color:#e6db74>&#39;email&#39;</span>] <span style=color:#f92672>=</span> emails[row[<span style=color:#e6db74>&#39;email&#39;</span>]]

        <span style=color:#75715e># Yield the row back to the caller</span>
        <span style=color:#66d9ef>yield</span> row


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>anonymize</span>(source, target):
    <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>    source is a path to a CSV file containing data to anonymize.
</span><span style=color:#e6db74>    target is a path to write the anonymized CSV data to.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    <span style=color:#66d9ef>with</span> open(source, <span style=color:#e6db74>&#39;rU&#39;</span>) <span style=color:#66d9ef>as</span> f:
        <span style=color:#66d9ef>with</span> open(target, <span style=color:#e6db74>&#39;w&#39;</span>) <span style=color:#66d9ef>as</span> o:
            <span style=color:#75715e># Use the DictReader to easily extract fields</span>
            reader <span style=color:#f92672>=</span> csv<span style=color:#f92672>.</span>DictReader(f)
            writer <span style=color:#f92672>=</span> csv<span style=color:#f92672>.</span>DictWriter(o, reader<span style=color:#f92672>.</span>fieldnames)

            <span style=color:#75715e># Read and anonymize data, writing to target file.</span>
            <span style=color:#66d9ef>for</span> row <span style=color:#f92672>in</span> anonymize_rows(reader):
                writer<span style=color:#f92672>.</span>writerow(row)

</code></pre></div><p>The entry point for this code is the <code>anonymize</code> function itself. It takes as input the path to two files: the <code>source</code>, where the target data is held in CSV form, and <code>target</code> a path to write out the anonymized data to. Both of these paths are opened for reading and writing respectively, then the <code>unicodecsv</code> module is used to read and parse each row, transforming them into Python dictionaries. Those dictionaries are passed into the <code>anonymize_rows</code> function, which transforms and <code>yields</code> each row to be written by the CSV writer to disk.</p><p>The <code>anonymize_rows</code> function takes any iterable of dictionaries which contain <code>name</code> and <code>email</code> keys. It loads the fake factory using <code>Factory.create</code> - a class function that loads various providers with methods that generate fake data (more on this later). We then create two <code>defaultdict</code> to map names to fake names and emails to fake emails.</p><p>The Python <code>collections</code> module provides the <code>defaultdict</code> which is similar to a regular <code>dict</code> except that if the key does not exist in the dictionary, a default value is supplied by the callable passed in at instantiation. For example, <code>d = defaultdict(int)</code> would provide a default value of 0 for every key not already in the dictionary. Therefore when we use <code>defaultdict(faker.name)</code> we&rsquo;re saying that for every key not in the dictionary, create a fake name (and similar for email). This allows us to generate a mapping of real data to fake data, and make sure that the real value always maps to the same fake value.</p><p>From there we simply iterate through all the rows, replacing data as necessary. If our target CSV file looked like this (imagine clickstream data from an email marketing campaign):</p><pre><code>name,email,value,time,ipaddr
James Hinglee,jhinglee@gmail.com,a,1446288248,202.12.32.123
Nancy Smithfield,unicorns4life@yahoo.com,b,1446288250,67.212.123.201
J. Hinglee,jhinglee@gmail.com,b,1446288271,202.12.32.123
</code></pre><p>It would be transformed to something as follows:</p><pre><code>Mr. Sharif Lehner,keion.hilll@gmail.com,a,1446288248,202.12.32.123
Webster Kulas,nienow.finnegan@gmail.com,b,1446288250,67.212.123.201
Maceo Turner MD,keion.hilll@gmail.com,b,1446288271,202.12.32.123
</code></pre><p>We now have a new wrangling tool in our toolbox that will allow us to transform CSVs with name and email fields into anonymized datasets! This naturally leads us to the question: what else can we anonymize?</p><h3 id=generating-fake-data>Generating Fake Data<a hidden class=anchor aria-hidden=true href=#generating-fake-data>#</a></h3><p>There are two third party libraries for generating fake data with Python that come up on Google search results: <a href=https://pypi.python.org/pypi/Faker>Faker</a> by <a href=https://github.com/deepthawtz>@deepthawtz</a> and <a href=https://pypi.python.org/pypi/fake-factory>Fake Factory</a> by <a href=https://github.com/joke2k>@joke2k</a>, which is also called “Faker”. Faker provides anonymization for user profile data, which is completely generated on a per-instance basis. Fake Factory (used in the example above) uses a providers approach to load many different fake data generators in multiple languages. Because Fake Factory has multiple language support, and a wider array of fake data generators, I typically use it over the more intuitive and simple to use Faker library which only does fake user profiles and we&rsquo;ll inspect it in detail for the rest of this post (everywhere except in this paragraph, when I refer to Faker, I&rsquo;m referring to Fake Factory).</p><p>The primary interface that Faker provides is called a <code>Generator</code>. Generators are a collection of <code>Provider</code> instances which are responsible for formatting random data for a particular domain. Generators also provide a wrapper around the <code>random</code> module, and allow you to set the random seed and other operations. While you could theoretically instantiate your own Generator with your own providers, Faker provides a <code>Factory</code> to automatically load all the providers on your behalf:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#f92672>from</span> faker <span style=color:#f92672>import</span> Factory
<span style=color:#f92672>&gt;&gt;&gt;</span> fake <span style=color:#f92672>=</span> Factory<span style=color:#f92672>.</span>create()
</code></pre></div><p>If you inspect the <code>fake</code> object, you&rsquo;ll see around 158 methods (at the time of this writing) that all generate fake data. Please allow me to highlight a few:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>credit_card_number()
<span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;180029425031151&#39;</span>
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>military_ship()
<span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;USCGC&#39;</span>
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> (fake<span style=color:#f92672>.</span>latitude(), fake<span style=color:#f92672>.</span>longitude())
(Decimal(<span style=color:#e6db74>&#39;-39.4682475&#39;</span>), Decimal(<span style=color:#e6db74>&#39;50.449170&#39;</span>))
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>hex_color()
<span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;#559135&#39;</span>
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>pyset(<span style=color:#ae81ff>3</span>)
set([<span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Et possimus.&#39;</span>, <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Blanditiis vero.&#39;</span>, <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Ad odio ad qui.&#39;</span>, <span style=color:#ae81ff>9855</span>])
</code></pre></div><p>Importantly, providers can also be localized using a language code; and this is probably the best reason to use the <code>Factory</code> object — to ensure that localized providers, or subsets of providers are loaded correctly. For example, to load the French localization:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake <span style=color:#f92672>=</span> Factory<span style=color:#f92672>.</span>create(<span style=color:#e6db74>&#39;fr_FR&#39;</span>)
<span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>catch_phrase_verb()
<span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;d&#39;atteindre vos buts&#34;</span>
</code></pre></div><p>And for fun, some Chinese:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake <span style=color:#f92672>=</span> Factory<span style=color:#f92672>.</span>create(<span style=color:#e6db74>&#39;cn_ZH&#39;</span>)
<span style=color:#f92672>&gt;&gt;&gt;</span> <span style=color:#66d9ef>print</span> fake<span style=color:#f92672>.</span>company()
<span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;快讯科技有限公司&#34;</span>
</code></pre></div><p>As you can see there are a wide variety of tools and techniques to generate fake data from a variety of domains. The best way to explore all the providers in detail is simply to look at the <a href=https://github.com/joke2k/faker/tree/master/faker/providers>providers package on GitHub</a>.</p><h3 id=creating-a-provider>Creating A Provider<a hidden class=anchor aria-hidden=true href=#creating-a-provider>#</a></h3><p>Although the Faker library has a very comprehensive array of providers, occasionally you need a domain specific fake data generator. In order to add a custom provider, you will need to subclass the <code>BaseProvider</code> and expose custom fake methods as class methods using the <code>@classmethod</code> decorator. One very easy approach is to create a set of random data you&rsquo;d like to expose, and simply randomly select it:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> faker.providers <span style=color:#f92672>import</span> BaseProvider

<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>OceanProvider</span>(BaseProvider):

    __provider__ <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;ocean&#34;</span>
    __lang__     <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;en_US&#34;</span>

    oceans <span style=color:#f92672>=</span> [
        <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Atlantic&#39;</span>, <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Pacific&#39;</span>, <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Indian&#39;</span>, <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Arctic&#39;</span>, <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Southern&#39;</span>,
    ]

    <span style=color:#a6e22e>@classmethod</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>ocean</span>(cls):
        <span style=color:#66d9ef>return</span> cls<span style=color:#f92672>.</span>random_element(cls<span style=color:#f92672>.</span>oceans)
</code></pre></div><p>In order to change the likelihood or distribution of which oceans are selected, simply add duplicates to the <code>oceans</code> list so that each name has the probability of selection that you&rsquo;d like. Then add your provider to the <code>Faker</code> object:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake <span style=color:#f92672>=</span> Factory<span style=color:#f92672>.</span>create()
<span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>add_provider(OceanProvider)
<span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>ocean()
<span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Indian&#39;</span>
</code></pre></div><p>In routine data wrangling operations, you may create a package structure with localization similar to how Faker is organized and load things on demand. Don&rsquo;t forget — if you come up with a generic provider that may be useful to many people, submit it back as a pull request!</p><h2 id=maintaining-data-quality>Maintaining Data Quality<a hidden class=anchor aria-hidden=true href=#maintaining-data-quality>#</a></h2><p>Now that we understand the wide variety of fake data we can generate, let&rsquo;s get back to our original example of creating user profile data of just name and email address. First, if you look at the results in the section above, we can make a few observations:</p><ul><li><strong>Pro</strong>: exact duplicates of name and email are maintained via the mapping.</li><li><strong>Pro</strong>: our user profiles are now fake data and PII is protected.</li><li><strong>Con</strong>: the name and the email are weird and don&rsquo;t match.</li><li><strong>Con</strong>: fuzzy duplicates (e.g. J. Smith vs. John Smith) are blown away.</li><li><strong>Con</strong>: all the domains are &ldquo;free email&rdquo; like Yahoo and Gmail.</li></ul><p>Basically we want to improve our user profile to include email addresses that are similar to the names (or a non-name based username), and we want to ensure that the domains are a bit more realistic for work addresses. We also want to include aliases, nicknames, or different versions of the name. Faker does provide a profile provider:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>simple_profile()
<span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;{</span>
  <span style=color:#e6db74>&#34;username&#34;</span>: <span style=color:#e6db74>&#34;autumn.weissnat&#34;</span>,
  <span style=color:#e6db74>&#34;name&#34;</span>: <span style=color:#e6db74>&#34;Jalyn Crona&#34;</span>,
  <span style=color:#e6db74>&#34;birthdate&#34;</span>: <span style=color:#e6db74>&#34;1981-01-29&#34;</span>,
  <span style=color:#e6db74>&#34;sex&#34;</span>: <span style=color:#e6db74>&#34;F&#34;</span>,
  <span style=color:#e6db74>&#34;address&#34;</span>: <span style=color:#e6db74>&#34;Unit 2875 Box 1477</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>DPO AE 18742-1954&#34;</span>,
  <span style=color:#e6db74>&#34;mail&#34;</span>: <span style=color:#e6db74>&#34;zollie.schamberger@hotmail.com&#34;</span>
}<span style=color:#e6db74>&#39;</span>
</code></pre></div><p>But as you can see, it suffers from the same problem. In this section, we&rsquo;ll explore different techniques that allow us to pass over the data and modify our fake data generation such that it matches the distributions we&rsquo;re seeing in the original data set. In particular we&rsquo;ll deal with the domain, creating more realistic fake profiles, and adding duplicates to our data set with fuzzy matching.</p><h3 id=domain-distribution>Domain Distribution<a hidden class=anchor aria-hidden=true href=#domain-distribution>#</a></h3><p>One idea to maintain the distribution of domains is to do a first pass over the data and create a mapping of real domain to fake domain. Moreover, many domains like gmail.com can be whitelisted and mapped directly to itself (we just need a fake username). Additionally, we can also preserve capitalization and spelling via this method, e.g. “Gmail.com” and “GMAIL.com” which might be important for data sets that have been entered by hand.</p><p>In order to create the domain mapping/whitelist, we&rsquo;ll need to create an object that can load a whitelist from disk, or generate one from our original dataset. I propose the following utility:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> csv
<span style=color:#f92672>import</span> json

<span style=color:#f92672>from</span> faker <span style=color:#f92672>import</span> Factory
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> Counter
<span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> MutableMapping

<span style=color:#66d9ef>class</span> <span style=color:#a6e22e>DomainMapping</span>(MutableMapping):

    <span style=color:#a6e22e>@classmethod</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>load</span>(cls, fobj):
        <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>        Load the mapping from a JSON file on disk.
</span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
        data <span style=color:#f92672>=</span> json<span style=color:#f92672>.</span>load(fobj)
        <span style=color:#66d9ef>return</span> cls(<span style=color:#f92672>**</span>data)

    <span style=color:#a6e22e>@classmethod</span>
    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>generate</span>(cls, emails):
        <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>        Pass through a list of emails and count domains to whitelist.
</span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
        <span style=color:#75715e># Count all the domains in each email address</span>
        counts  <span style=color:#f92672>=</span> Counter([
            email<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;@&#34;</span>)[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>] <span style=color:#66d9ef>for</span> email <span style=color:#f92672>in</span> emails
        ])

        <span style=color:#75715e># Create a domain mapping</span>
        domains <span style=color:#f92672>=</span> cls()

        <span style=color:#75715e># Ask the user what domains to whitelist based on frequency</span>
        <span style=color:#66d9ef>for</span> idx, (domain, count) <span style=color:#f92672>in</span> enumerate(counts<span style=color:#f92672>.</span>most_common())):
            prompt <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;{}/{}: Whitelist {} ({} addresses)?&#34;</span><span style=color:#f92672>.</span>format(
                idx<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>, len(counts), domain, count
            )

            <span style=color:#66d9ef>print</span> prompt
            ans <span style=color:#f92672>=</span> raw_input(<span style=color:#e6db74>&#34;[y/n/q] &gt; &#34;</span>)<span style=color:#f92672>.</span>lower()

            <span style=color:#66d9ef>if</span> ans<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#39;y&#39;</span>):
                <span style=color:#75715e># Whitelist the domain</span>
                domains[domain] <span style=color:#f92672>=</span> domain
            <span style=color:#66d9ef>elif</span> ans<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#39;n&#39;</span>):
                <span style=color:#75715e># Create a fake domain</span>
                domains[domain]
            <span style=color:#66d9ef>elif</span> ans<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#39;q&#39;</span>):
                <span style=color:#66d9ef>break</span>
            <span style=color:#66d9ef>else</span>:
                <span style=color:#66d9ef>continue</span>

        <span style=color:#66d9ef>return</span> domains  

    <span style=color:#66d9ef>def</span> __init__(self, whitelist<span style=color:#f92672>=</span>[], mapping<span style=color:#f92672>=</span>{}):
        <span style=color:#75715e># Create the domain mapping properties</span>
        self<span style=color:#f92672>.</span>fake    <span style=color:#f92672>=</span> Factory<span style=color:#f92672>.</span>create()
        self<span style=color:#f92672>.</span>domains <span style=color:#f92672>=</span> mapping

        <span style=color:#75715e># Add the whitelist as a mapping to itself.</span>
        <span style=color:#66d9ef>for</span> domain <span style=color:#f92672>in</span> whitelist:
            self<span style=color:#f92672>.</span>domains[domain] <span style=color:#f92672>=</span> domain

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>dump</span>(self, fobj):
        <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>        Dump the domain mapping whitelist/mapping to JSON.
</span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
        whitelist <span style=color:#f92672>=</span> []
        mapping   <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>domains<span style=color:#f92672>.</span>copy()
        <span style=color:#66d9ef>for</span> key <span style=color:#f92672>in</span> mapping<span style=color:#f92672>.</span>keys():
            <span style=color:#66d9ef>if</span> key <span style=color:#f92672>==</span> mapping[key]:
                whitelist<span style=color:#f92672>.</span>append(mapping<span style=color:#f92672>.</span>pop(key))

        json<span style=color:#f92672>.</span>dump({
            <span style=color:#e6db74>&#39;whitelist&#39;</span>: whitelist,
            <span style=color:#e6db74>&#39;mapping&#39;</span>: mapping
        }, fobj, indent<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>)

    <span style=color:#66d9ef>def</span> __getitem__(self, key):
        <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>        Get a fake domain for a real domain.
</span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
        <span style=color:#66d9ef>if</span> key <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>domains:
            self<span style=color:#f92672>.</span>domains[key] <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>fake<span style=color:#f92672>.</span>domain_name()
        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>domains[key]

    <span style=color:#66d9ef>def</span> __setitem__(self, key, val):
        self<span style=color:#f92672>.</span>domains[key] <span style=color:#f92672>=</span> val

    <span style=color:#66d9ef>def</span> __delitem__(self, key):
        <span style=color:#66d9ef>del</span> self<span style=color:#f92672>.</span>domains[key]

    <span style=color:#66d9ef>def</span> __iter__(self):
        <span style=color:#66d9ef>for</span> key <span style=color:#f92672>in</span> self<span style=color:#f92672>.</span>domains:
            <span style=color:#66d9ef>yield</span> key
</code></pre></div><p>Right so that&rsquo;s quite a lot of code all at once, so let&rsquo;s break it down a bit. First, the class extends <code>MutableMapping</code> which is an abstract base class in the <code>collections</code> module. The ABC gives us the ability to make this class act just like a <code>dict</code> object. All we have to do is provide <code>__getitem__</code>, <code>__setitem__</code>, <code>__delitem__</code>, and <code>__iter__</code> methods and all other dictionary methods like <code>pop</code>, or <code>values</code> work on our behalf. Here, we&rsquo;re just wrapping an inner dictionary called <code>domains</code>.</p><p>The thing to note about our <code>__getitem__</code> method is that it acts very similar to a <code>defaultdict</code>, that is if you try to fetch a key that is not in the mapping, then it generates fake data on your behalf. This way, any domains that we don&rsquo;t have in our whitelist or mapping will automatically be anonymized.</p><p>Next, we want to be able to <code>load</code> and <code>dump</code> this data to a JSON file on disk, that way we can maintain our mapping between anonymization runs. The <code>load</code> method is fairly straight forward, it just takes an open file-like object and parses it uses the <code>json</code> module, and instantiates the domain mapping and returns it. The <code>dump</code> method is a bit more complex, it has to break down the whitelist and mapping into separate objects, so that we can easily modify the data on disk if needed. Together, these methods will allow you to load and save your mapping into a JSON file that will look similar to:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json>{
    <span style=color:#f92672>&#34;whitelist&#34;</span>: [
        <span style=color:#e6db74>&#34;gmail.com&#34;</span>,
        <span style=color:#e6db74>&#34;yahoo.com&#34;</span>
    ],
    <span style=color:#f92672>&#34;mapping&#34;</span>: {
        <span style=color:#f92672>&#34;districtdatalabs.com&#34;</span>: <span style=color:#e6db74>&#34;fadel.org&#34;</span>,
        <span style=color:#f92672>&#34;umd.edu&#34;</span>: <span style=color:#e6db74>&#34;ferrystanton.org&#34;</span>
    }
}
</code></pre></div><p>The final method of note is the <code>generate</code> method. The generate method allows you to do a first pass through a list of emails, count the frequency of the domains, then propose to the user in order of most frequent domain whether or not to add it to the whitelist. For each domain in the emails, the user is prompted as follows:</p><pre><code>1/245: Whitelist &quot;gmail.com&quot; (817 addresses)?
[y/n/q] &gt;
</code></pre><p>Note that the prompt includes a progress indicator (this is prompt 1 of 245) as well as a method to quit early. This is especially important for large datasets that have a lot of single domains; if you quit, the domains will still be faked, and the user only sees the most frequent examples for whitelisting. The idea behind this mechanism to read through your CSV once, generate the whitelist, then save it to disk so that you can use it for anonymization on a routine basis. Moreover, you can modify domains in the JSON file to better match any semantics you might have (e.g. include .edu or .gov domains, which are not generated by the internet provider in Faker).</p><h3 id=realistic-profiles>Realistic Profiles<a hidden class=anchor aria-hidden=true href=#realistic-profiles>#</a></h3><p>To create realistic profiles, we&rsquo;ll create a provider that uses the domain map from above and generates fake data for every combination we see in the data set. This provider will also provide opportunities for mapping multiple names and email addresses to a single profile so that we can use the profile for creating fuzzy duplicates in the next section. Here is the code:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Profile</span>(object):

    <span style=color:#66d9ef>def</span> __init__(self, domains):
        self<span style=color:#f92672>.</span>domains <span style=color:#f92672>=</span> domains
        self<span style=color:#f92672>.</span>generator <span style=color:#f92672>=</span> Factory<span style=color:#f92672>.</span>create()

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fuzzy_profile</span>(self, name<span style=color:#f92672>=</span>None, email<span style=color:#f92672>=</span>None):
        <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>        Return an profile that allows for fuzzy names and emails.
</span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
        parts <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>fuzzy_name_parts()
        <span style=color:#66d9ef>return</span> {
            <span style=color:#e6db74>&#34;names&#34;</span>: {name: self<span style=color:#f92672>.</span>fuzzy_name(parts, name)},
            <span style=color:#e6db74>&#34;emails&#34;</span>: {email: self<span style=color:#f92672>.</span>fuzzy_email(parts, email)},
        }

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fuzzy_name_parts</span>(self):
        <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>        Returns first, middle, and last name parts
</span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
        <span style=color:#66d9ef>return</span> (
            self<span style=color:#f92672>.</span>generator<span style=color:#f92672>.</span>first_name(),
            self<span style=color:#f92672>.</span>generator<span style=color:#f92672>.</span>first_name(),
            self<span style=color:#f92672>.</span>generator<span style=color:#f92672>.</span>last_name()
        )

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fuzzy_name</span>(self, parts, name<span style=color:#f92672>=</span>None):
        <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>        Creates a name that has similar case to the passed in name.
</span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
        <span style=color:#75715e># Extract the first, initial, and last name from the parts.</span>
        first, middle, last <span style=color:#f92672>=</span> parts

        <span style=color:#75715e># Create the name, with chance of middle or initial included.</span>
        chance <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>generator<span style=color:#f92672>.</span>random_digit()
        <span style=color:#66d9ef>if</span> chance <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>2</span>:
            fname <span style=color:#f92672>=</span> <span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;{} {}. {}&#34;</span><span style=color:#f92672>.</span>format(first, middle[<span style=color:#ae81ff>0</span>], last)
        <span style=color:#66d9ef>elif</span> chance <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>4</span>:
            fname <span style=color:#f92672>=</span> <span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;{} {} {}&#34;</span><span style=color:#f92672>.</span>format(first, middle, last)
        <span style=color:#66d9ef>else</span>:
            fname <span style=color:#f92672>=</span> <span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;{} {}&#34;</span><span style=color:#f92672>.</span>format(first, last)

        <span style=color:#66d9ef>if</span> name <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> None:
            <span style=color:#75715e># Match the capitalization of the name</span>
            <span style=color:#66d9ef>if</span> name<span style=color:#f92672>.</span>isupper(): <span style=color:#66d9ef>return</span> fname<span style=color:#f92672>.</span>upper()
            <span style=color:#66d9ef>if</span> name<span style=color:#f92672>.</span>islower(): <span style=color:#66d9ef>return</span> fname<span style=color:#f92672>.</span>lower()

        <span style=color:#66d9ef>return</span> fname

    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>fuzzy_email</span>(self, parts, email<span style=color:#f92672>=</span>None):
        <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>        Creates an email similar to the name and original email.
</span><span style=color:#e6db74>        &#34;&#34;&#34;</span>
        <span style=color:#75715e># Extract the first, initial, and last name from the parts.</span>
        first, middle, last <span style=color:#f92672>=</span> parts

        <span style=color:#75715e># Use the domain mapping to identify the fake domain.</span>
        <span style=color:#66d9ef>if</span> email <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> None:
            domain <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>domains[email<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;@&#34;</span>)[<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>]]
        <span style=color:#66d9ef>else</span>:
            domain <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>generator<span style=color:#f92672>.</span>domain_name()

        <span style=color:#75715e># Create the username based on the name parts</span>
        chance <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>generator<span style=color:#f92672>.</span>random_digit()
        <span style=color:#66d9ef>if</span> chance <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>2</span>:
            username <span style=color:#f92672>=</span> <span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;{}.{}&#34;</span><span style=color:#f92672>.</span>format(first, last)
        <span style=color:#66d9ef>elif</span> chance <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>3</span>:
            username <span style=color:#f92672>=</span> <span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;{}.{}.{}&#34;</span><span style=color:#f92672>.</span>format(first, middle[<span style=color:#ae81ff>0</span>], last)
        <span style=color:#66d9ef>elif</span> chance <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>6</span>:
            username <span style=color:#f92672>=</span> <span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;{}{}&#34;</span><span style=color:#f92672>.</span>format(first[<span style=color:#ae81ff>0</span>], last)
        <span style=color:#66d9ef>elif</span> chance <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>8</span>:
            username <span style=color:#f92672>=</span> last
        <span style=color:#66d9ef>else</span>:
            username <span style=color:#f92672>=</span> <span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;{}{}&#34;</span><span style=color:#f92672>.</span>format(
                first, self<span style=color:#f92672>.</span>generator<span style=color:#f92672>.</span>random_number()
            )

        <span style=color:#75715e># Match the case of the email</span>
        <span style=color:#66d9ef>if</span> email <span style=color:#f92672>is</span> <span style=color:#f92672>not</span> None:
            <span style=color:#66d9ef>if</span> email<span style=color:#f92672>.</span>islower(): username <span style=color:#f92672>=</span> username<span style=color:#f92672>.</span>lower()
            <span style=color:#66d9ef>if</span> email<span style=color:#f92672>.</span>isupper(): username <span style=color:#f92672>=</span> username<span style=color:#f92672>.</span>upper()
        <span style=color:#66d9ef>else</span>:
            username <span style=color:#f92672>=</span> username<span style=color:#f92672>.</span>lower()

        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>u</span><span style=color:#e6db74>&#34;{}@{}&#34;</span><span style=color:#f92672>.</span>format(username, domain)
</code></pre></div><p>Again, this is a lot of code, make sure you go through it carefully so you understand what is happening. First off, a profile in this case is the combination of a mapping of names to fake names and emails to fake emails. The key is that the names and emails are related to original data somehow. In this case, the relationship is through case such that &ldquo;DANIEL WEBSTER&rdquo; is faked to &ldquo;JAKOB WILCOTT&rdquo; instead of to &ldquo;Jakob Wilcott&rdquo;. Additionally through our domain mapping, we also maintain the relationship of the original email domain to the fake domain mapping, e.g. everyone with the an email domain &ldquo;@districtdatalabs.com&rdquo; will be mapped to the same fake domain.</p><p>In order to maintain the relationship of names to emails (which is very common), we need to be able to access the name more directly. In this case we have a name parts generator which generates fake first, middle, and last names. We then randomly generate names of the form &ldquo;first last&rdquo;, &ldquo;first middle last&rdquo;, or &ldquo;first i. last&rdquo; with random chance. Additionally the email can take a variety of forms based on the name parts as well. Now we get slightly more realistic profiles:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>fuzzy_profile()
{<span style=color:#e6db74>&#39;names&#39;</span>: {None: <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Zaire Ebert&#39;</span>}, <span style=color:#e6db74>&#39;emails&#39;</span>: {None: <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;ebert@von.com&#39;</span>}}
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> fake<span style=color:#f92672>.</span>fuzzy_profile(
<span style=color:#f92672>...</span>    name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;Daniel Webster&#39;</span>, email<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;dictionaryguy@gmail.com&#39;</span>)
{<span style=color:#e6db74>&#39;names&#39;</span>: {<span style=color:#e6db74>&#39;Daniel Webster&#39;</span>: <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;Georgia McDermott&#39;</span>},
 <span style=color:#e6db74>&#39;emails&#39;</span>: {<span style=color:#e6db74>&#39;dictionaryguy@gmail.com&#39;</span>: <span style=color:#e6db74>u</span><span style=color:#e6db74>&#39;georgia9@gmail.com&#39;</span>}}
</code></pre></div><p>Importantly this profile object makes it easy to map multiple names and emails to the same profile object to create &ldquo;fuzzy&rdquo; profiles and duplicates in your dataset. We will discuss how to perform fuzzy matching in the next section.</p><h3 id=fuzzing-fake-names-from-duplicates>Fuzzing Fake Names from Duplicates<a hidden class=anchor aria-hidden=true href=#fuzzing-fake-names-from-duplicates>#</a></h3><p>If you noticed in our original data set we had the situation where we had a clear entity duplication: same email, but different names. In fact, the second name was simply the first initial and last name but you could imagine other situations like nicknames (&ldquo;Bill&rdquo; instead of &ldquo;William&rdquo;), or having both work and personal emails in the dataset. The fuzzy profile objects we generated in the last section allow us to maintain a mapping of all name parts to generated fake names, but we need some way to be able to detect duplicates and combine their profile: enter the <code>fuzzywuzzy</code> module.</p><pre><code>$ pip install fuzzywuzzy python-Levenshtein
</code></pre><p>Similar to how we did the domain mapping, we&rsquo;re going to pass through the entire dataset and look for similar name, email pairs and propose them to the user. If the user thinks they&rsquo;re duplicates, then we&rsquo;ll merge them together into a single profile, and use the mappings as we anonymize. Although I won&rsquo;t go through an entire object to do this as with the domain map, this is also something you can save to disk and load on demand for multiple anonymization passes and to include user based edits.</p><p>The first step is to get pairs, and eliminate exact duplicates. To do this we&rsquo;ll create a hashable data structure for our profiles using a <code>namedtuple</code>.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> namedtuple
<span style=color:#f92672>from</span> itertools <span style=color:#f92672>import</span> combinations

Person <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#39;Person&#39;</span>, <span style=color:#e6db74>&#39;name, email&#39;</span>)


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>pairs_from_rows</span>(rows):
    <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>    Expects rows of dictionaries with name and email keys.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    <span style=color:#75715e># Create a set of person tuples (no exact duplicates)</span>
    people <span style=color:#f92672>=</span> set([
        Person(row[<span style=color:#e6db74>&#39;name&#39;</span>], row[<span style=color:#e6db74>&#39;email&#39;</span>]) <span style=color:#66d9ef>for</span> row <span style=color:#f92672>in</span> rows
    ])

    <span style=color:#75715e># Yield ordered pairs of people objects without replacement</span>
    <span style=color:#66d9ef>for</span> pair <span style=color:#f92672>in</span> combinations(people, <span style=color:#ae81ff>2</span>):
        <span style=color:#66d9ef>yield</span> pair
</code></pre></div><p>The <code>namedtuple</code> is an immutable data structure that is compact, efficient, and allows us to access properties by name. Because it is immutable it is also hashable (unlike mutable dictionaries), meaning we can use it as keys in sets and dictionaries. This is important, because the first thing our <code>pairs_from_rows</code> function does is eliminate exact matches by creating a set of <code>Person</code> tuples. We then use the <code>combinations</code> function in <code>itertools</code> to generate every pair without replacement.</p><p>The next step is to figure out how similar each pair is. To do this we&rsquo;ll use the <code>fuzzywuzzy</code> library to come up with a partial ratio score: the mean of the similarity of the names and the emails for each pair:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> fuzzywuzzy <span style=color:#f92672>import</span> fuzz
<span style=color:#f92672>from</span> functools <span style=color:#f92672>import</span> partial

<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>normalize</span>(value, email<span style=color:#f92672>=</span>False):
    <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>    Make everything lowercase and remove spaces.
</span><span style=color:#e6db74>    If email, only take the username portion to compare.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    <span style=color:#66d9ef>if</span> email:
        value <span style=color:#f92672>=</span> value<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#34;@&#34;</span>)[<span style=color:#ae81ff>0</span>]
    <span style=color:#66d9ef>return</span> value<span style=color:#f92672>.</span>lower()<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#34; &#34;</span>, <span style=color:#e6db74>&#34;&#34;</span>)


<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>person_similarity</span>(pair):
    <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>    Returns the mean of the normalized partial ratio scores.
</span><span style=color:#e6db74>    &#34;&#34;&#34;</span>
    <span style=color:#75715e># Normalize the names and the emails</span>
    names <span style=color:#f92672>=</span> map(normalize, [p<span style=color:#f92672>.</span>name <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> pair])
    email <span style=color:#f92672>=</span> map(
        partial(normalize, email<span style=color:#f92672>=</span>True), [p<span style=color:#f92672>.</span>email <span style=color:#66d9ef>for</span> p <span style=color:#f92672>in</span> pair]
    )

    <span style=color:#75715e># Compute the partial ratio scores for both names and emails</span>
    scores <span style=color:#f92672>=</span> [
        fuzz<span style=color:#f92672>.</span>partial_ratio(a, b) <span style=color:#66d9ef>for</span> a, b <span style=color:#f92672>in</span> [names, emails]
    ]

    <span style=color:#75715e># Return the mean score of the pair</span>
    <span style=color:#66d9ef>return</span> float(sum(scores)) <span style=color:#f92672>/</span> len(scores)
</code></pre></div><p>The score will be between 0 (no similarity) and 100 (exact match), though hopefully you won&rsquo;t get any scores of 100 since we eliminated exact matches above. For example:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>&gt;&gt;&gt;</span> person_similarity([
<span style=color:#f92672>...</span>     Person(<span style=color:#e6db74>&#39;John Lennon&#39;</span>, <span style=color:#e6db74>&#39;john.lennon@gmail.com&#39;</span>),
<span style=color:#f92672>...</span>     Person(<span style=color:#e6db74>&#39;J. Lennon&#39;</span>, <span style=color:#e6db74>&#39;jlennon@example.org&#39;</span>)
<span style=color:#f92672>...</span> ])
<span style=color:#ae81ff>80.5</span>
</code></pre></div><p>The fuzzing process will go through your entire dataset, and create pairs of people it finds and compute their similarity score. Filter all pairs except for scores that meet a threshold (say, 50) then propose them to the user to decide if they&rsquo;re duplicates in descending score order. When a duplicate is found, merge the profile object to map the new names and emails together.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>Anonymization of datasets is a critical method to promote the exploration and practice of data science through open data. Fake data generators that already exist give us the opportunity to ensure that private data is obfuscated. This issue becomes how to leverage these fake data generators while still maintaining a high quality dataset with semantic relations preserved for further analysis. As we&rsquo;ve seen throughout the post, even just the anonymization of just two fields, name and email can lead to potential problems.</p><p>This problem, and the code in this post are associated with a real case study. For District Data Labs' Entity Resolution Research Lab<a href=#apd-footnote-3>3</a> I wanted to create a dataset that removed PII of DDL members while maintaining duplicates and structure to study entity resolution. The source dataset was 1,343 records in CSV form and contained name and emails that I wanted to anonymize.</p><p>Using the strategy I mentioned for domain name mapping, the dataset contained 245 distinct domain names, 185 of which were hapax legomena (appeared only once). There was a definite long tail, as the first 20 or so most frequent domains were the majority of the records. Once I generated the whitelist as above, I manually edited the mappings to ensure that there were no duplicates and that major work domains were “professional enough”.</p><p>Using the fuzzy matching process was also a bear. It took on average, 28 seconds to compute the pairwise scores. Using a threshold score of 50, I was proposed 5,110 duplicates (out of a possible 901,153 combinations). I went through 354 entries (until the score was below 65) and was satisfied that I covered many of the duplicates in the dataset.</p><p>In the end the dataset that I anonymized was of a high quality. It obfuscated personally identifying information like name and email and I&rsquo;m happy to make the data set public. Of course, you could reverse the some of the information in the dataset. For example, I&rsquo;m listed in the dataset, and one of the records indicates a relationship between a fake user and a blog post, which I&rsquo;m on record as having written. However, even though you can figure out who I am and what else I&rsquo;ve done in the dataset, you wouldn&rsquo;t be able to use it to extract my email address, which was the goal.</p><p>In the end, anonymizing a dataset is a lot of work, with a lot of gotchas and hoops to jump through. However, I hope you will agree that it is invaluable in an open data context. By sharing data, resources, and tools we can use many eyes to provide multiple insights and to drive data science forward.</p><h3 id=footnotes>Footnotes<a hidden class=anchor aria-hidden=true href=#footnotes>#</a></h3><p>1. <a href="http://www.google.com/search?q=define:anonymize">Anonymize</a>: remove identifying particulars from (test results) for statistical or other purposes.</p><p>2. <a href=http://www.slideshare.net/BenjaminBengfort/a-primer-on-entity-resolution>Entity Resolution</a>: tools or techniques that identify, group, and link digital mentions or manifestations of some object in the real world.</p><p>3. <a href=http://www.districtdatalabs.com/research-lab>DDL Research Labs</a> is an applied research program intended to develop novel, innovative data science solutions towards practical applications.</p></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2021 <a href=https://bbengfort.github.io>Libelli</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById('menu')
menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>