<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Unique Values in Python: A Benchmark | Libelli</title><meta name=keywords content><meta name=description content="An interesting question came up in the development of Yellowbrick: given a vector of values, what is the quickest way to get the unique values? Ok, so maybe this isn&rsquo;t a terribly interesting question, however the results surprised us and may surprise you as well. First we&rsquo;ll do a little background, then I&rsquo;ll give the results and then discuss the benchmarking method.
The problem comes up in Yellowbrick when we want to get the discrete values for a target vector, y — a problem that comes up in classification tasks."><meta name=author content="Benjamin Bengfort"><link rel=canonical href=https://bbengfort.github.io/2017/05/python-unique-benchmark/><link crossorigin=anonymous href=/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://bbengfort.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bbengfort.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://bbengfort.github.io/icon.png><link rel=apple-touch-icon href=https://bbengfort.github.io/apple-touch-icon-precomposed.png><link rel=mask-icon href=https://bbengfort.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-D3BE7EHHVP"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D3BE7EHHVP",{anonymize_ip:!1})}</script><meta property="og:title" content="Unique Values in Python: A Benchmark"><meta property="og:description" content="An interesting question came up in the development of Yellowbrick: given a vector of values, what is the quickest way to get the unique values? Ok, so maybe this isn&rsquo;t a terribly interesting question, however the results surprised us and may surprise you as well. First we&rsquo;ll do a little background, then I&rsquo;ll give the results and then discuss the benchmarking method.
The problem comes up in Yellowbrick when we want to get the discrete values for a target vector, y — a problem that comes up in classification tasks."><meta property="og:type" content="article"><meta property="og:url" content="https://bbengfort.github.io/2017/05/python-unique-benchmark/"><meta property="og:image" content="https://bbengfort.github.io/bear.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-05-02T14:24:18+00:00"><meta property="article:modified_time" content="2017-05-02T14:24:18+00:00"><meta property="og:site_name" content="Libelli"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bbengfort.github.io/bear.png"><meta name=twitter:title content="Unique Values in Python: A Benchmark"><meta name=twitter:description content="An interesting question came up in the development of Yellowbrick: given a vector of values, what is the quickest way to get the unique values? Ok, so maybe this isn&rsquo;t a terribly interesting question, however the results surprised us and may surprise you as well. First we&rsquo;ll do a little background, then I&rsquo;ll give the results and then discuss the benchmarking method.
The problem comes up in Yellowbrick when we want to get the discrete values for a target vector, y — a problem that comes up in classification tasks."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://bbengfort.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Unique Values in Python: A Benchmark","item":"https://bbengfort.github.io/2017/05/python-unique-benchmark/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Unique Values in Python: A Benchmark","name":"Unique Values in Python: A Benchmark","description":"An interesting question came up in the development of Yellowbrick: given a vector of values, what is the quickest way to get the unique values? Ok, so maybe this isn\u0026rsquo;t a terribly interesting question, however the results surprised us and may surprise you as well. First we\u0026rsquo;ll do a little background, then I\u0026rsquo;ll give the results and then discuss the benchmarking method.\nThe problem comes up in Yellowbrick when we want to get the discrete values for a target vector, y — a problem that comes up in classification tasks.","keywords":[],"articleBody":"An interesting question came up in the development of Yellowbrick: given a vector of values, what is the quickest way to get the unique values? Ok, so maybe this isn’t a terribly interesting question, however the results surprised us and may surprise you as well. First we’ll do a little background, then I’ll give the results and then discuss the benchmarking method.\nThe problem comes up in Yellowbrick when we want to get the discrete values for a target vector, y — a problem that comes up in classification tasks. By getting the unique set of values we know the number of classes, as well as the class names. This information is necessary during visualization because it is vital in assigning colors to individual classes. Therefore in a Visualizer we might have a method as follows:\nclass ScatterVisualizer(Visualizer): def fit(X, y=None): labels = [ str(item) for item in set(y) ] colors = dict(zip((labels, resolve_colors(len(labels))))) ... NOTE: a related question is how can we determine a continuous vector y (a regression problem) from a categorical vector y (a classification problem) automatically? This allows us to assign a sequential vs. discrete colors to the target variable.\nTo make a short story even shorter, when I reviewed the above code, my response was: “isn’t something like np.unique faster?”. I was returned a simple “yep, sure is” answer, and the code was changed to np.unique — job done, right? When the commit was pushed, a few tests didn’t pass; it looked like there was an issue converting a Python data type into the numpy data type to pass to the unique function (turns out this was not the issue), but that caused me to investigate the input type to the uniqueness method. Using set vs. np.unique depends on if the input type is a Python list or a Numpy array, as we’ll see shortly.\nSo let’s get into results. We proposed three methods of getting the unique items from our target vector:\nimport numpy as np from sklearn.preprocessing import LabelEncoder def py_unique(data): return list(set(data)) def np_unique(data): return np.unique(data) def sk_unique(data): encoder = LabelEncoder() encoder.fit(data) return encoder.classes_ The first converts a Python set into a list and returns the unsorted list of unique values. The second uses numpy and converts the input into a np.array; it actually returns a sorted array of values. The third option is more directly related to Scikit-Learn, fitting a LabelEncoder transformer and getting the unique classes from that.\nBefore getting into the benchmarking methodology, the results are as follow:\nThe results in the above figure show that by far the fastest unique computation is using set on a Python list. This is especially surprising given the fact that numpy arrays are C implementations, and are therefore guaranteed to be blazingly fast. Using np.unique is on average faster than everything else, and it certainly gives the best performance on array data structures out of all the methods. It does slightly worse with Python lists, but not as badly as Python does with array structures. Scikit-Learn clearly adds some overhead, especially when it comes to Python lists, but performs fairly well for array structs.\nIn the end, we chose to stick with np.unique in Yellowbrick, primarily because the expected input is in fact a np.array, either from data loaded from np.loadtxt or from a Pandas Series or DataFrame. If a Python list is passed in, then the performance is adequate for our needs. Still, the performance gaps based on input type were a surprise and I would encourage you, as always, to benchmark code and not just rely on traditional assumptions!\nNOTE: If you believe that our implementation or benchmarking can be improved, please let me know!\nBenchmarking Notes Benchmarking, especially in Python, is a tricky task. Therefore, in order to be as transparent as possible in the claims made above and to quickly catch any mistakes, I present the benchmarking methodology here. The complete script and notebook can be found on Gist.\nFirst, I will say that I did explore the timeit module for benchmarking, but couldn’t make these particular tests work with it. Instead, I wrote a simple timing function that returns the time delta in microseconds (μs). I also wrote a benchmark function that applied the unique method to a dataset n=10000 times and returned the average time for an operation.\ndef timeit(func): start = time.time() func() return ((time.time() - start) * 1000000.0) def benchmark(func, data, n=10000): delta = sum([ timeit(lambda: func(data)) for _ in range(n) ]) return (float(delta) / float(n)) Because a set operation is at worst O(n) and therefore depends on the length of the dataset, I created a function to make a dataset of a variable length with between 1 and 52 unique elements. This data was then stored as a Python list or as a Numpy array object depending on the input tested.\ndef make_data(uniques=10, length=10000): chars = string.ascii_letters if uniques \u003e len(chars): raise ValueError(\"too many uniques for the choices\") return [ random.choice(chars[:uniques]) for idx in range(length) ] The actual test protocol ran on datasets whose length went from 10 to 100,000 items by a factor of ten each time (e.g. 10, 100, 1000, etc.). The test also factored different numbers of unique values from 1 to 40 by 5. Each dataset was then benchmarked as a list and an array against the three _unique methods for a total of 195 benchmarks.\nAs you can see, the amount of time per operation increases exponentially as the length of the dataset increases:\nAnd it appears (as expected) that the number of unique values per dataset does not have a meaningful impact on the operation time:\nHopefully these timing numbers and approach to benchmarking seem valid. They certainly work to highlight interesting places where our coding assumptions might fail us.\n","wordCount":"963","inLanguage":"en","datePublished":"2017-05-02T14:24:18Z","dateModified":"2017-05-02T14:24:18Z","author":{"@type":"Person","name":"Benjamin Bengfort"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bbengfort.github.io/2017/05/python-unique-benchmark/"},"publisher":{"@type":"Organization","name":"Libelli","logo":{"@type":"ImageObject","url":"https://bbengfort.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://bbengfort.github.io accesskey=h title="Libelli (Alt + H)"><img src=https://bbengfort.github.io/icon.png alt aria-label=logo height=35>Libelli</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://bbengfort.github.io/archive/ title=archive><span>archive</span></a></li><li><a href=https://bbengfort.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://bbengfort.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://bbengfort.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://bbengfort.github.io>Home</a>&nbsp;»&nbsp;<a href=https://bbengfort.github.io/posts/>Posts</a></div><h1 class=post-title>Unique Values in Python: A Benchmark</h1><div class=post-meta><span title='2017-05-02 14:24:18 +0000 UTC'>May 2, 2017</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;963 words&nbsp;·&nbsp;Benjamin Bengfort&nbsp;|&nbsp;<a href=https://github.com/bbengfort/bbengfort.github.io/tree/main/content/posts/2017-05-02-python-unique-benchmark.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>An interesting question came up in the development of <a href=http://www.scikit-yb.org/>Yellowbrick</a>: given a vector of values, what is the quickest way to get the unique values? Ok, so maybe this isn&rsquo;t a terribly interesting question, however the results surprised us and may surprise you as well. First we&rsquo;ll do a little background, then I&rsquo;ll give the results and then discuss the benchmarking method.</p><p>The problem comes up in Yellowbrick when we want to get the discrete values for a target vector, <code>y</code> — a problem that comes up in classification tasks. By getting the unique set of values we know the number of classes, as well as the class names. This information is necessary during visualization because it is vital in assigning colors to individual classes. Therefore in a Visualizer we might have a method as follows:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ScatterVisualizer</span><span class=p>(</span><span class=n>Visualizer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>labels</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=nb>str</span><span class=p>(</span><span class=n>item</span><span class=p>)</span> <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=nb>set</span><span class=p>(</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>colors</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(</span><span class=nb>zip</span><span class=p>((</span><span class=n>labels</span><span class=p>,</span> <span class=n>resolve_colors</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>labels</span><span class=p>)))))</span>
</span></span><span class=line><span class=cl>        <span class=o>...</span>
</span></span></code></pre></div><p><strong>NOTE</strong>: a related question is how can we determine a continuous vector <code>y</code> (a regression problem) from a categorical vector <code>y</code> (a classification problem) automatically? This allows us to assign a sequential vs. discrete colors to the target variable.</p><p>To make a short story even shorter, when I reviewed the above code, my response was: “isn&rsquo;t something like <code>np.unique</code> faster?”. I was returned a simple “yep, sure is” answer, and the code was changed to <code>np.unique</code> — job done, right? When the commit was pushed, a few tests didn&rsquo;t pass; it looked like there was an issue converting a Python data type into the numpy data type to pass to the unique function (turns out this was not the issue), but that caused me to investigate the input type to the uniqueness method. Using <code>set</code> vs. <code>np.unique</code> depends on if the input type is a Python <code>list</code> or a Numpy <code>array</code>, as we&rsquo;ll see shortly.</p><p>So let&rsquo;s get into results. We proposed three methods of getting the unique items from our target vector:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.preprocessing</span> <span class=kn>import</span> <span class=n>LabelEncoder</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>py_unique</span><span class=p>(</span><span class=n>data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=nb>list</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>data</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>np_unique</span><span class=p>(</span><span class=n>data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>unique</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>sk_unique</span><span class=p>(</span><span class=n>data</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>encoder</span> <span class=o>=</span> <span class=n>LabelEncoder</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>encoder</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>encoder</span><span class=o>.</span><span class=n>classes_</span>
</span></span></code></pre></div><p>The first converts a Python <code>set</code> into a <code>list</code> and returns the <em>unsorted</em> list of unique values. The second uses numpy and converts the input into a <code>np.array</code>; it actually returns a <em>sorted</em> array of values. The third option is more directly related to Scikit-Learn, fitting a <code>LabelEncoder</code> transformer and getting the unique classes from that.</p><p>Before getting into the benchmarking methodology, the results are as follow:</p><p><a href=/images/2017-05-02-time-per-op-by-input.png><img loading=lazy src=/images/2017-05-02-time-per-op-by-input.png alt="Average Time per Method by Input Type"></a></p><p>The results in the above figure show that by far the fastest unique computation is using <code>set</code> on a Python list. This is especially surprising given the fact that numpy arrays are C implementations, and are therefore guaranteed to be blazingly fast. Using <code>np.unique</code> is on average faster than everything else, and it certainly gives the best performance on <code>array</code> data structures out of all the methods. It does slightly worse with Python lists, but not as badly as Python does with <code>array</code> structures. Scikit-Learn clearly adds some overhead, especially when it comes to Python lists, but performs fairly well for <code>array</code> structs.</p><p>In the end, we chose to stick with <code>np.unique</code> in Yellowbrick, primarily because the expected input is in fact a <code>np.array</code>, either from data loaded from <code>np.loadtxt</code> or from a Pandas Series or DataFrame. If a Python list is passed in, then the performance is adequate for our needs. Still, the performance gaps based on input type were a surprise and I would encourage you, as always, to benchmark code and not just rely on traditional assumptions!</p><p><strong>NOTE</strong>: If you believe that our implementation or benchmarking can be improved, please let me know!</p><h2 id=benchmarking-notes>Benchmarking Notes<a hidden class=anchor aria-hidden=true href=#benchmarking-notes>#</a></h2><p>Benchmarking, especially in Python, is a tricky task. Therefore, in order to be as transparent as possible in the claims made above and to quickly catch any mistakes, I present the benchmarking methodology here. The <a href=https://gist.github.com/bbengfort/bed86721ecb20fd96269606c05741851>complete script and notebook</a> can be found on Gist.</p><p>First, I will say that I did explore the <a href=https://docs.python.org/3.5/library/timeit.html><code>timeit</code> module</a> for benchmarking, but couldn&rsquo;t make these particular tests work with it. Instead, I wrote a simple timing function that returns the time delta in microseconds (μs). I also wrote a benchmark function that applied the unique method to a dataset <code>n=10000</code> times and returned the average time for an operation.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>timeit</span><span class=p>(</span><span class=n>func</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>func</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>((</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span><span class=p>)</span> <span class=o>*</span> <span class=mf>1000000.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>benchmark</span><span class=p>(</span><span class=n>func</span><span class=p>,</span> <span class=n>data</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>delta</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=n>timeit</span><span class=p>(</span><span class=k>lambda</span><span class=p>:</span> <span class=n>func</span><span class=p>(</span><span class=n>data</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>(</span><span class=nb>float</span><span class=p>(</span><span class=n>delta</span><span class=p>)</span> <span class=o>/</span> <span class=nb>float</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>
</span></span></code></pre></div><p>Because a set operation is at worst <code>O(n)</code> and therefore depends on the length of the dataset, I created a function to make a dataset of a variable length with between 1 and 52 unique elements. This data was then stored as a Python <code>list</code> or as a Numpy <code>array</code> object depending on the input tested.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>make_data</span><span class=p>(</span><span class=n>uniques</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>length</span><span class=o>=</span><span class=mi>10000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>chars</span> <span class=o>=</span> <span class=n>string</span><span class=o>.</span><span class=n>ascii_letters</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>uniques</span> <span class=o>&gt;</span> <span class=nb>len</span><span class=p>(</span><span class=n>chars</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;too many uniques for the choices&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>chars</span><span class=p>[:</span><span class=n>uniques</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>idx</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>length</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span></code></pre></div><p>The actual test protocol ran on datasets whose length went from 10 to 100,000 items by a factor of ten each time (e.g. 10, 100, 1000, etc.). The test also factored different numbers of unique values from 1 to 40 by 5. Each dataset was then benchmarked as a <code>list</code> and an <code>array</code> against the three <code>_unique</code> methods for a total of 195 benchmarks.</p><p>As you can see, the amount of time per operation increases exponentially as the length of the dataset increases:</p><p><a href=/images/2017-05-02-time-per-length-by-method.png><img loading=lazy src=/images/2017-05-02-time-per-length-by-method.png alt="Average Time with Increasing Input Size by Method"></a></p><p>And it appears (as expected) that the number of unique values per dataset does not have a meaningful impact on the operation time:</p><p><a href=/images/2017-05-02-time-per-unique-by-method.png><img loading=lazy src=/images/2017-05-02-time-per-unique-by-method.png alt="Average Time with Increasing Uniques by Method"></a></p><p>Hopefully these timing numbers and approach to benchmarking seem valid. They certainly work to highlight interesting places where our coding assumptions might fail us.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://bbengfort.github.io/2017/05/in-process-caches/><span class=title>« Prev</span><br><span>In Process Cacheing</span></a>
<a class=next href=https://bbengfort.github.io/2017/04/throughput/><span class=title>Next »</span><br><span>Measuring Throughput</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://bbengfort.github.io>Libelli</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>