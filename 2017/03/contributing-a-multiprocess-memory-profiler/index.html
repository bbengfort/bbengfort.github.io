<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Contributing a Multiprocess Memory Profiler | Libelli</title><meta name=keywords content><meta name=description content="In this post I wanted to catalog the process of an open source contribution I was a part of, which added a feature to the memory profiler Python library by Fabian Pedregosa and Philippe Gervais. It&rsquo;s a quick story to tell but took over a year to complete, and I learned a lot from the process. I hope that the story is revealing, particularly to first time contributors and shows that even folks that have been doing this for a long time still have to find ways to positively approach collaboration in an open source environment."><meta name=author content="Benjamin Bengfort"><link rel=canonical href=https://bbengfort.github.io/2017/03/contributing-a-multiprocess-memory-profiler/><link crossorigin=anonymous href=/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe+FVUFzPh7U=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://bbengfort.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bbengfort.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://bbengfort.github.io/icon.png><link rel=apple-touch-icon href=https://bbengfort.github.io/apple-touch-icon-precomposed.png><link rel=mask-icon href=https://bbengfort.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-D3BE7EHHVP"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-D3BE7EHHVP",{anonymize_ip:!1})}</script><meta property="og:title" content="Contributing a Multiprocess Memory Profiler"><meta property="og:description" content="In this post I wanted to catalog the process of an open source contribution I was a part of, which added a feature to the memory profiler Python library by Fabian Pedregosa and Philippe Gervais. It&rsquo;s a quick story to tell but took over a year to complete, and I learned a lot from the process. I hope that the story is revealing, particularly to first time contributors and shows that even folks that have been doing this for a long time still have to find ways to positively approach collaboration in an open source environment."><meta property="og:type" content="article"><meta property="og:url" content="https://bbengfort.github.io/2017/03/contributing-a-multiprocess-memory-profiler/"><meta property="og:image" content="https://bbengfort.github.io/bear.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-03-20T11:42:58+00:00"><meta property="article:modified_time" content="2017-03-20T11:42:58+00:00"><meta property="og:site_name" content="Libelli"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bbengfort.github.io/bear.png"><meta name=twitter:title content="Contributing a Multiprocess Memory Profiler"><meta name=twitter:description content="In this post I wanted to catalog the process of an open source contribution I was a part of, which added a feature to the memory profiler Python library by Fabian Pedregosa and Philippe Gervais. It&rsquo;s a quick story to tell but took over a year to complete, and I learned a lot from the process. I hope that the story is revealing, particularly to first time contributors and shows that even folks that have been doing this for a long time still have to find ways to positively approach collaboration in an open source environment."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://bbengfort.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Contributing a Multiprocess Memory Profiler","item":"https://bbengfort.github.io/2017/03/contributing-a-multiprocess-memory-profiler/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Contributing a Multiprocess Memory Profiler","name":"Contributing a Multiprocess Memory Profiler","description":"In this post I wanted to catalog the process of an open source contribution I was a part of, which added a feature to the memory profiler Python library by Fabian Pedregosa and Philippe Gervais. It\u0026rsquo;s a quick story to tell but took over a year to complete, and I learned a lot from the process. I hope that the story is revealing, particularly to first time contributors and shows that even folks that have been doing this for a long time still have to find ways to positively approach collaboration in an open source environment.","keywords":[],"articleBody":"In this post I wanted to catalog the process of an open source contribution I was a part of, which added a feature to the memory profiler Python library by Fabian Pedregosa and Philippe Gervais. It’s a quick story to tell but took over a year to complete, and I learned a lot from the process. I hope that the story is revealing, particularly to first time contributors and shows that even folks that have been doing this for a long time still have to find ways to positively approach collaboration in an open source environment. I also think it’s a fairly standard example of how contributions work in practice and perhaps this story will help us all think about how to better approach the pull request process.\nThe bottom line is that a feature that was relatively quick to prototype took a long time to get included into the main code, even though there was a lot of interest. The hangup involved all the normal excuses (too busy, worried the code wasn’t good enough, etc.) but in the end it was effective, clear, and positive communication that finally made things come together. Here’s how it went down in timeline form:\nJuly 13, 2016: asked a Stack Overflow question: How to profile multiple subprocesses using Python multiprocessing and memory_profiler?\nUnfortunately I can’t remember exactly why I was asking this, but my best guess is that I was trying to determine memory usage either for the minke parallel NLP application or to do some benchmarking for my research simulations. There are unfortunately no blog posts around that time that hint at what I was doing.\nJuly 14, 2016: submitted a feature request, mprof each child process independently, to the memory_profiler repository.\nAt this point, I received some feedback from @fabianp directing me to some specific locations in code where I might start making changes. Unfortunately I don’t know where those comments were added, potentially in an another issue? I forked the project and began a proof of concept.\nJuly 16, 2016: proof of concept, mpmprof created in my repository fork.\nI submitted a comment on the issue to ask @fabianp to take a look at my fork. He (correctly) asked for a pull request. However, I was unsure that my proof of concept was good enough for a PR and asked for help and got a minor comment in return. I decided to try to fix it and I made a critical mistake: I didn’t submit the PR.\nAugust 4, 2016 - March 18, 2017: the contribution silence occurs.\nPings and plus ones from @cachedout and @davidgbe bring the project up to my attention again, but it feels like a daunting amount of work, so things stay silent.\nMarch 18, 2017: finally I submit a “work in progress (WIP)” pull request, WIP: Independent child process monitoring #118.\nThis pull request is very brief and simply has my original contribution along with a massive fork update to get to the latest code. However, it is finally at this point that @fabianp takes a look at my code. He asks me to merge my proof of concept into the codebase.\nMarch 20, 2017: I address the merge request with a very simple implementation, code review begins.\nThe code review is a back and forth conversation between @fabianp and I. He tests and runs the example code on his machine, and takes a look at the modifications I made specifically. Any changes or updates requested I can commit to my fork and they are automatically included in the pull request.\nMarch 21, 2017: my submitted pull request is merged.\nWe ended up going back and forth a few times, discussing the impact of multiprocessing on various components and a pickle error that cropped up. The conversation was very good and it led to quite a few updates to the code, and even a couple of changes from @fabianp. Throughout I became more confident since he was looking at the PR and testing it.\nMarch 22, 2017: new release of memory_profiler on PyPI.\nThe release was posted on PyPI along with a nice thank you on Twitter. I can finally answer my own question on Stack Overflow!\nThanks to @bbengfort memory_profiler can now separately track memory usage of forked processes https://t.co/LCOMLgNzM8 pic.twitter.com/Lc46lf0xs8\n— Fabian Pedregosa (@fpedregosa) March 22, 2017 So let me break down what happened here and do a bit of a post-mortem. First, I had a problem that I wanted to solve with an existing, popular, and well-used codebase (namely track the memory usage of child processes independently to the main process). I thought there must be a way to do this, and while there was a solution to a variant of my problem, there was no direct solution.\nNext, I decided to fix the problem and start a conversation. I was able to (relatively quickly) create a concept that solved my problem. In fact, it worked so well that I used that solution for a little under a year. I thought that by maintaining my solution in my fork, other folks were able to leverage it.\nHowever, there was a problem: I wasn’t able to contribute back to the main library. So let’s look at what held me back:\nThe changes to the primary module were modest but the changes to the implementation were drastic Fear that I had broken something unrelated since there weren’t a lot of tests Style clash: how I write code is different from how this module is constructed. It was easier for me to write my proof of concept outside the original module Specifically, I was able to make the modifications to memory_profiler.py (the library for the code base) by adding a function and modifying the control flow of the primary entry point. This felt relatively safe and non-invasive. However, modifying the command-line script, mprof required a lot more work. It was simpler and faster for me to write my own command line script, mpmprof rather than modify the original version.\nFrankly, if you compare mprof and mpmprof I think it’s pretty obvious that there are two drastically different coding styles at work here. I use the argparse library, have things structured functionally rather than with if/else control syntax, have a different docstring implementation, more intermediate functions, use regular expressions for parsing, and have a bit more exception handling (just to name a few notable differences). However, I also did not have a complete implementation from the other code, nor did I completely understand all the problems the original code was trying to solve.\nI thought I faced a problem about whether I should update the code to use argparse and “more modern” syntax (there was even an related pull request) or to potentially introduce breaking changes by trying to stay as close to the original as possible. I even considered forking the project and creating my own, potentially more easily maintained-by-me version. I worried that I was being a jerk by overhauling the code, or not contributing “the right way”. But really the problem was that I wasn’t engaging the authors of the library in a meaningful discussion.\nSo what would I do next time to solve the problem? Open a pull request as soon as possible.\nMaybe I thought Fabian would go checkout my fork or maybe I let the list of barriers hold me back, but whatever the case not submitting a PR meant that I couldn’t engage the authors in a discussion about my contribution. I had heard the PR ASAP advice before, but it hasn’t been until recently that I have fully understood what GitHub and the code review tools allow you to do. Contribution is collaboration and the PR workflow helps you get there!\nI haven’t fully implemented all of my changes to the code base (again, for the reasons outlined above) but now, if you run:\n$ pip install -U memory_profiler $ mprof run -M python examples/multiprocessing_example.py $ mprof plot You’ll get a figure that looks something similar to:\nThis is great news for an oft-requested feature of a library that is well used and well maintained. For reference, if you’d like to see an example of my proof of concept, you can check out my fork, or see my version of the mprof script on Gist. However, you don’t have to worry about that gist, and can instead simply pip install memory_profiler to get access to this feature!\n","wordCount":"1409","inLanguage":"en","datePublished":"2017-03-20T11:42:58Z","dateModified":"2017-03-20T11:42:58Z","author":{"@type":"Person","name":"Benjamin Bengfort"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bbengfort.github.io/2017/03/contributing-a-multiprocess-memory-profiler/"},"publisher":{"@type":"Organization","name":"Libelli","logo":{"@type":"ImageObject","url":"https://bbengfort.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://bbengfort.github.io accesskey=h title="Libelli (Alt + H)"><img src=https://bbengfort.github.io/icon.png alt aria-label=logo height=35>Libelli</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://bbengfort.github.io/archive/ title=archive><span>archive</span></a></li><li><a href=https://bbengfort.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://bbengfort.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://bbengfort.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://bbengfort.github.io>Home</a>&nbsp;»&nbsp;<a href=https://bbengfort.github.io/posts/>Posts</a></div><h1 class=post-title>Contributing a Multiprocess Memory Profiler</h1><div class=post-meta><span title='2017-03-20 11:42:58 +0000 UTC'>March 20, 2017</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1409 words&nbsp;·&nbsp;Benjamin Bengfort&nbsp;|&nbsp;<a href=https://github.com/bbengfort/bbengfort.github.io/tree/main/content/posts/2017-03-20-contributing-a-multiprocess-memory-profiler.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>In this post I wanted to catalog the process of an open source contribution I was a part of, which added a feature to the <a href=https://pypi.python.org/pypi/memory_profiler/>memory profiler</a> Python library by <a href=http://fseoane.net/>Fabian Pedregosa</a> and <a href=https://github.com/pgervais>Philippe Gervais</a>. It&rsquo;s a quick story to tell but took over a year to complete, and I learned a lot from the process. I hope that the story is revealing, particularly to first time contributors and shows that even folks that have been doing this for a long time still have to find ways to positively approach collaboration in an open source environment. I also think it&rsquo;s a fairly standard example of how contributions work in practice and perhaps this story will help us all think about how to better approach the pull request process.</p><p>The bottom line is that a feature that was relatively quick to prototype took a long time to get included into the main code, even though there was a lot of interest. The hangup involved all the normal excuses (too busy, worried the code wasn&rsquo;t good enough, etc.) but in the end it was effective, clear, and positive communication that finally made things come together. Here&rsquo;s how it went down in timeline form:</p><ul><li><p><strong>July 13, 2016</strong>: asked a Stack Overflow question: <em><a href=http://stackoverflow.com/questions/38358881/how-to-profile-multiple-subprocesses-using-python-multiprocessing-and-memory-pro>How to profile multiple subprocesses using Python multiprocessing and memory_profiler?</a></em></p><p>Unfortunately I can&rsquo;t remember exactly why I was asking this, but my best guess is that I was trying to determine memory usage either for the <a href=https://github.com/bbengfort/minke>minke</a> parallel NLP application or to do some benchmarking for my research simulations. There are unfortunately no blog posts around that time that hint at what I was doing.</p></li><li><p><strong>July 14, 2016</strong>: submitted a feature request, <a href=https://github.com/fabianp/memory_profiler/issues/118>mprof each child process independently</a>, to the memory_profiler repository.</p><p>At this point, I received some feedback from <a href=https://github.com/fabianp>@fabianp</a> directing me to some specific locations in code where I might start making changes. Unfortunately I don&rsquo;t know where those comments were added, potentially in an another issue? I forked the project and began a proof of concept.</p></li><li><p><strong>July 16, 2016</strong>: proof of concept, <a href=https://gist.github.com/bbengfort/574e0b5acf0068527f74bba897538dcb>mpmprof</a> created in <a href=https://github.com/bbengfort/memory_profiler/>my repository fork</a>.</p><p>I submitted a comment on the issue to ask <a href=https://github.com/fabianp>@fabianp</a> to take a look at my fork. He (correctly) asked for a pull request. However, I was unsure that my proof of concept was good enough for a PR and asked for help and got a minor comment in return. I decided to try to fix it and I made a critical mistake: I didn&rsquo;t submit the PR.</p></li><li><p><strong>August 4, 2016 - March 18, 2017</strong>: the contribution silence occurs.</p><p>Pings and plus ones from <a href=https://github.com/cachedout>@cachedout</a> and <a href=https://github.com/davidgbe>@davidgbe</a> bring the project up to my attention again, but it feels like a daunting amount of work, so things stay silent.</p></li><li><p><strong>March 18, 2017</strong>: finally I submit a “work in progress (WIP)” pull request, <a href=https://github.com/fabianp/memory_profiler/pull/134>WIP: Independent child process monitoring #118</a>.</p><p>This pull request is very brief and simply has my original contribution along with a massive fork update to get to the latest code. However, it is finally at this point that <a href=https://github.com/fabianp>@fabianp</a> takes a look at my code. He asks me to merge my proof of concept into the codebase.</p></li><li><p><strong>March 20, 2017</strong>: I address the merge request with a very simple implementation, code review begins.</p><p>The code review is a back and forth conversation between <a href=https://github.com/fabianp>@fabianp</a> and I. He tests and runs the example code on his machine, and takes a look at the modifications I made specifically. Any changes or updates requested I can commit to my fork and they are automatically included in the pull request.</p></li><li><p><strong>March 21, 2017</strong>: my submitted pull request is merged.</p><p>We ended up going back and forth a few times, discussing the impact of multiprocessing on various components and a pickle error that cropped up. The conversation was very good and it led to quite a few updates to the code, and even a couple of changes from <a href=https://github.com/fabianp>@fabianp</a>. Throughout I became more confident since he was looking at the PR and testing it.</p></li><li><p><strong>March 22, 2017</strong>: new release of memory_profiler on PyPI.</p><p>The release was posted on PyPI along with a <a href=https://twitter.com/fpedregosa/status/844492791048814594>nice thank you on Twitter</a>. I can finally answer my own question on Stack Overflow!</p><blockquote class=twitter-tweet><p lang=en dir=ltr>Thanks to <a href="https://twitter.com/bbengfort?ref_src=twsrc%5Etfw">@bbengfort</a> memory_profiler can now separately track memory usage of forked processes <a href=https://t.co/LCOMLgNzM8>https://t.co/LCOMLgNzM8</a> <a href=https://t.co/Lc46lf0xs8>pic.twitter.com/Lc46lf0xs8</a></p>&mdash; Fabian Pedregosa (@fpedregosa) <a href="https://twitter.com/fpedregosa/status/844492791048814594?ref_src=twsrc%5Etfw">March 22, 2017</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script></li></ul><p>So let me break down what happened here and do a bit of a post-mortem. First, I had a problem that I wanted to solve with an existing, popular, and well-used codebase (namely track the memory usage of child processes independently to the main process). I thought there must be a way to do this, and while there was a solution to a variant of my problem, there was no direct solution.</p><p>Next, I decided to fix the problem and start a conversation. I was able to (relatively quickly) create a concept that solved my problem. In fact, it worked so well that I used that solution for a little under a year. I thought that by maintaining my solution in my fork, other folks were able to leverage it.</p><p>However, there was a problem: I wasn&rsquo;t able to contribute back to the main library. So let&rsquo;s look at what held me back:</p><ol><li>The changes to the primary module were modest but the changes to the implementation were drastic</li><li>Fear that I had broken something unrelated since there weren&rsquo;t a lot of tests</li><li>Style clash: how I write code is different from how this module is constructed.</li><li>It was easier for me to write my proof of concept outside the original module</li></ol><p>Specifically, I was able to make the modifications to <code>memory_profiler.py</code> (the library for the code base) by adding a function and modifying the control flow of the primary entry point. This felt relatively safe and non-invasive. However, modifying the command-line script, <code>mprof</code> required a lot more work. It was simpler and faster for me to write my own command line script, <code>mpmprof</code> rather than modify the original version.</p><p>Frankly, if you compare <code>mprof</code> and <code>mpmprof</code> I think it&rsquo;s pretty obvious that there are two drastically different coding styles at work here. I use the <code>argparse</code> library, have things structured functionally rather than with if/else control syntax, have a different docstring implementation, more intermediate functions, use regular expressions for parsing, and have a bit more exception handling (just to name a few notable differences). However, I also did not have a complete implementation from the other code, nor did I completely understand all the problems the original code was trying to solve.</p><p>I thought I faced a problem about whether I should update the code to use <code>argparse</code> and “more modern” syntax (there was even an related <a href=https://github.com/fabianp/memory_profiler/pull/128>pull request</a>) or to potentially introduce breaking changes by trying to stay as close to the original as possible. I even considered forking the project and creating my own, potentially more easily maintained-by-me version. I worried that I was being a jerk by overhauling the code, or not contributing “the right way”. But really the problem was that I wasn&rsquo;t engaging the authors of the library in a meaningful discussion.</p><p>So what would I do next time to solve the problem? <strong>Open a pull request as soon as possible</strong>.</p><p>Maybe I thought Fabian would go checkout my fork or maybe I let the list of barriers hold me back, but whatever the case not submitting a PR meant that I couldn&rsquo;t engage the authors in a discussion about my contribution. I had heard the PR ASAP advice before, but it hasn&rsquo;t been until recently that I have fully understood what GitHub and the code review tools allow you to do. Contribution is collaboration and the PR workflow helps you get there!</p><p>I haven&rsquo;t fully implemented all of my changes to the code base (again, for the reasons outlined above) but now, if you run:</p><pre tabindex=0><code>$ pip install -U memory_profiler
$ mprof run -M python examples/multiprocessing_example.py
$ mprof plot
</code></pre><p>You&rsquo;ll get a figure that looks something similar to:</p><p><a href=/images/2017-03-20-mprof-multiprocessing-plot.png><img loading=lazy src=/images/2017-03-20-mprof-multiprocessing-plot.png alt="Memory Profiler Multiprocessing Example"></a></p><p>This is great news for an oft-requested feature of a library that is well used and well maintained. For reference, if you&rsquo;d like to see an example of my proof of concept, you can check out my fork, or see my version of the <code>mprof</code> script <a href=https://gist.github.com/bbengfort/574e0b5acf0068527f74bba897538dcb>on Gist</a>. However, you don&rsquo;t have to worry about that gist, and can instead simply <code>pip install memory_profiler</code> to get access to this feature!</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://bbengfort.github.io/2017/03/sanely-grpc-dial-a-remote/><span class=title>« Prev</span><br><span>Sanely gRPC Dial a Remote</span></a>
<a class=next href=https://bbengfort.github.io/2017/03/pseudo-merkle-tree/><span class=title>Next »</span><br><span>Pseudo Merkle Tree</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://bbengfort.github.io>Libelli</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>