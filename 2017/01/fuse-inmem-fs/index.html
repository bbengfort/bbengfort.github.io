<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>In-Memory File System with FUSE | Libelli</title><meta name=keywords content><meta name=description content="The Filesystem in Userspace (FUSE) software interface allows developers to create file systems without editing kernel code. This is especially useful when creating replicated file systems, file protocols, backup systems, or other computer systems that require intervention for FS operations but not an entire operating system. FUSE works by running the FS code as a user process while FUSE provides a bridge through a request/response protocol to the kernel.
In Go, the FUSE library is implemented by bazil."><meta name=author content="Benjamin Bengfort"><link rel=canonical href=https://bbengfort.github.io/2017/01/fuse-inmem-fs/><link crossorigin=anonymous href=/assets/css/stylesheet.min.d0c0348c2d0cff14148d0e347258519d8df2ce53ce5ac32c7bd9a549182cb8ae.css integrity="sha256-0MA0jC0M/xQUjQ40clhRnY3yzlPOWsMse9mlSRgsuK4=" rel="preload stylesheet" as=style><link rel=preload href=/icon.png as=image><script defer crossorigin=anonymous src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><link rel=icon href=https://bbengfort.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://bbengfort.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://bbengfort.github.io/icon.png><link rel=apple-touch-icon href=https://bbengfort.github.io/apple-touch-icon-precomposed.png><link rel=mask-icon href=https://bbengfort.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.79.0"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-8096804-11','auto');ga('send','pageview');}</script><meta property="og:title" content="In-Memory File System with FUSE"><meta property="og:description" content="The Filesystem in Userspace (FUSE) software interface allows developers to create file systems without editing kernel code. This is especially useful when creating replicated file systems, file protocols, backup systems, or other computer systems that require intervention for FS operations but not an entire operating system. FUSE works by running the FS code as a user process while FUSE provides a bridge through a request/response protocol to the kernel.
In Go, the FUSE library is implemented by bazil."><meta property="og:type" content="article"><meta property="og:url" content="https://bbengfort.github.io/2017/01/fuse-inmem-fs/"><meta property="og:image" content="https://bbengfort.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2017-01-30T16:17:26+00:00"><meta property="article:modified_time" content="2017-01-30T16:17:26+00:00"><meta property="og:site_name" content="Libelli"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://bbengfort.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="In-Memory File System with FUSE"><meta name=twitter:description content="The Filesystem in Userspace (FUSE) software interface allows developers to create file systems without editing kernel code. This is especially useful when creating replicated file systems, file protocols, backup systems, or other computer systems that require intervention for FS operations but not an entire operating system. FUSE works by running the FS code as a user process while FUSE provides a bridge through a request/response protocol to the kernel.
In Go, the FUSE library is implemented by bazil."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://bbengfort.github.io/posts/"},{"@type":"ListItem","position":3,"name":"In-Memory File System with FUSE","item":"https://bbengfort.github.io/2017/01/fuse-inmem-fs/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"In-Memory File System with FUSE","name":"In-Memory File System with FUSE","description":"The Filesystem in Userspace (FUSE) software interface allows developers to create file systems without editing kernel code. This is especially useful when creating replicated file systems, file protocols, backup systems, or other computer systems that require intervention for FS operations but not an entire operating system. FUSE works by running the FS code as a user process while FUSE provides a bridge through a request/response protocol to the kernel.\nIn Go, the FUSE library is implemented by bazil.","keywords":[],"articleBody":"The Filesystem in Userspace (FUSE) software interface allows developers to create file systems without editing kernel code. This is especially useful when creating replicated file systems, file protocols, backup systems, or other computer systems that require intervention for FS operations but not an entire operating system. FUSE works by running the FS code as a user process while FUSE provides a bridge through a request/response protocol to the kernel.\nIn Go, the FUSE library is implemented by bazil.org/fuse. It is a from-scratch implementation of the kernel-userspace communication protocol and does not use the C library. The library has been excellent for research implementations, particularly because Go is such an excellent language (named programming language of 2016). However, it does lead to some questions (particularly because of the questions in the Go documentation):\n How is the performance of bazil.org/fuse? How complete is the implementation of bazil.org/fuse? How does bazil.org/fuse compare to a native system?  In order to start taking a look at these questions, I created an in-memory file system using bazil.org/fuse called MemFS. The bazil.org/fuse library works by providing many interfaces to define a File System (fs.FS* interfaces), Nodes (fs.Node* interfaces) that represent files, links, and directories, and Handles (fs.Handle* interfaces) to open files. A file system that uses bazil.org/fuse must create Go objects that implement these interfaces then pass them to the FUSE server which makes calls to the relevant methods. The goal of MemFS was to provide as complete an implementation of every single interface as possible (since I have yet to find a reference implementation that does do this).\nIn order to evaluate the performance of MemFS vs. the normal file system on my MacBook pro, I created the following protocol, implemented by a simple Python script:\n Clone a repository into the file system Make/build the software in the repository Traverse the file system and stat every file Collect time and FS meta data information  I then compared MemFS performance to normal FS performance for several popular large and small C applications including databases, web servers, and programming languages:\n Redis (76MB, 591 files, 137,475 LOC) Postgres (422MB, 4,807 files, 910,948 LOC) Nginx (62MB, 440 files, 155,056 LOC) Apache Web Server (362MB, 4,059 files, 503,006 LOC) Ruby (197MB, 3,281 files, 918,052 LOC) Python 3 (382MB, 3,570 files, 931,814 LOC)  Unfortunately due to vagaries in the build process with Postgres, Apache Httpd, Ruby, and Python I can only report on Redis and Nginx. But more on that later.\nThe workload code can be found at github.com/bbengfort/compile-workload along with a benchmark.sh script that executes the full test-suite. Here are the time results for the OS X file system (OS X) vs. MemFS for both cloning and compiling:\nAs you can see from the graphs, git clone is horribly slow on MemFS. Further investigation revealed that git is writing 4107 bytes of data at a time as it downloads its compressed pack file. This means approximately 255 times more calls to the Write() FUSE method than other file writing mechanisms which typically write 1MB at a time. Because each call to Write() must be handled by the FUSE server and responded to by MemFS (which is allocating an byte slice under the hood), the more calls to Write() the exponentially worse the system is.\nCompiling, on the other hand, is supposed to be more representative of a workload - containing many reads, writes, and stats in a controlled sequence of events. For both Redis and Nginx, MemFS does add some overhead to compilation, but not nearly as much as git clone did. Note that downloading a zip file from GitHub and then building it exhibited a similar shape to the compiling graph.\nMemory usage for MemFS is currently atrocious, however:\nThe dotted lines are the maximum file usage on disk according to a recursive stat of each file. The solid lines are the memory usage of MemFS during clone and build. Although some extra memory overhead is expected to maintain the journal and references to the file system tree, the amount of overhead necessary seems completely out of whack compared to the storage requirements. Some investigation about freeing data is necessary.\nFinally the last, critical lesson. The reason only Redis and Nginx are represented in the graph is because the other builds failed for one reason or another. The cause of the build failures is primarily due to my goal to implement 100% of the FUSE interface methods. However this is not how bazil.org/fuse works and in fact 100% interface implementation is exactly the wrong thing to do.\nTake for example the ReadAll() vs. Read() methods that implement HandleReadAller and HandleReader respectively. I attempted to implement both and kept receiving different build errors, though I did notice the clone and compile behavior changing as I messed with these two methods. It turns out that the bazil.org/fuse server implementation checks to see if the FS implements HandleReadAller and if so, returns the result from ReadAll, otherwise it enforces HandleRead and sends the Read method the request and response from FUSE.\nMy hypothesis as to why cloning was failing when I had implemented ReadAll is simple. The Read method allows the client to specify an offset in the file to read from and a size of data to respond with. Presumably git clone was attempting to read the last 32 bytes of the compressed pack file (or something like that) so it could perform a CRC check or some other data validation. FUSE, however, returned all of the data rather than just the data from the offset because ReadAll was implemented. As a result, git clone choked with a stream error.\nThe bottom line is that FUSE allows some interfaces for convenience only for higher level FS implementations. MemFS, however, needs to support only the low level FUSE serve interactions. As a general rule of thumb, if the interface method takes a request and response object and simply returns an error - then that FUSE method is probably at a bit lower of a level, exactly what MemFS is looking for.\n","wordCount":"1008","inLanguage":"en","datePublished":"2017-01-30T16:17:26Z","dateModified":"2017-01-30T16:17:26Z","author":{"@type":"Person","name":"Benjamin Bengfort"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://bbengfort.github.io/2017/01/fuse-inmem-fs/"},"publisher":{"@type":"Organization","name":"Libelli","logo":{"@type":"ImageObject","url":"https://bbengfort.github.io/favicon.ico"}}}</script></head><body id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme: #1d1e20;--entry: #2e2e33;--primary: rgba(255, 255, 255, 0.84);--secondary: rgba(255, 255, 255, 0.56);--tertiary: rgba(255, 255, 255, 0.16);--content: rgba(255, 255, 255, 0.74);--hljs-bg: #2e2e33;--code-bg: #37383e;--border: #333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://bbengfort.github.io accesskey=h title="Libelli (Alt + H)"><img src=/icon.png alt=logo aria-label=logo height=35>Libelli</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://bbengfort.github.io/archive/ title=archive><span>archive</span></a></li><li><a href=https://bbengfort.github.io/categories/ title=categories><span>categories</span></a></li><li><a href=https://bbengfort.github.io/search/ title="search (Alt + /)" accesskey=/><span>search</span></a></li><li><a href=https://bbengfort.github.io/about/ title=about><span>about</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>In-Memory File System with FUSE</h1><div class=post-meta>January 30, 2017&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Benjamin Bengfort</div></header><div class=post-content><p>The <a href=https://en.wikipedia.org/wiki/Filesystem_in_Userspace>Filesystem in Userspace (FUSE)</a> software interface allows developers to create file systems without editing kernel code. This is especially useful when creating replicated file systems, file protocols, backup systems, or other computer systems that require intervention for FS operations but not an entire operating system. FUSE works by running the FS code as a user process while FUSE provides a bridge through a request/response protocol to the kernel.</p><p>In Go, the FUSE library is implemented by <a href=https://github.com/bazil/fuse>bazil.org/fuse</a>. It is a from-scratch implementation of the kernel-userspace communication protocol and does not use the C library. The library has been excellent for research implementations, particularly because Go is such an excellent language (named <a href=http://www.tiobe.com/tiobe-index/>programming language of 2016</a>). However, it does lead to some questions (particularly because of the questions in the Go documentation):</p><ol><li>How is the performance of bazil.org/fuse?</li><li>How complete is the implementation of bazil.org/fuse?</li><li>How does bazil.org/fuse compare to a native system?</li></ol><p>In order to start taking a look at these questions, I created an in-memory file system using bazil.org/fuse called <a href=https://github.com/bbengfort/memfs>MemFS</a>. The bazil.org/fuse library works by providing many interfaces to define a File System (<a href=https://godoc.org/bazil.org/fuse/fs#FS><code>fs.FS*</code> interfaces</a>), Nodes (<a href=https://godoc.org/bazil.org/fuse/fs#Node><code>fs.Node*</code> interfaces</a>) that represent files, links, and directories, and Handles (<a href=https://godoc.org/bazil.org/fuse/fs#Handle><code>fs.Handle*</code> interfaces</a>) to open files. A file system that uses bazil.org/fuse must create Go objects that implement these interfaces then pass them to the FUSE server which makes calls to the relevant methods. The goal of MemFS was to provide as complete an implementation of every single interface as possible (since I have yet to find a reference implementation that does do this).</p><p>In order to evaluate the performance of MemFS vs. the normal file system on my MacBook pro, I created the following protocol, implemented by a simple Python script:</p><ol><li>Clone a repository into the file system</li><li>Make/build the software in the repository</li><li>Traverse the file system and stat every file</li><li>Collect time and FS meta data information</li></ol><p>I then compared MemFS performance to normal FS performance for several popular large and small C applications including databases, web servers, and programming languages:</p><ol><li><a href=https://github.com/antirez/redis>Redis</a> (76MB, 591 files, 137,475 LOC)</li><li><a href=https://github.com/postgres/postgres>Postgres</a> (422MB, 4,807 files, 910,948 LOC)</li><li><a href=https://github.com/nginx/nginx>Nginx</a> (62MB, 440 files, 155,056 LOC)</li><li><a href=https://github.com/apache/httpd>Apache Web Server</a> (362MB, 4,059 files, 503,006 LOC)</li><li><a href=https://github.com/ruby/ruby>Ruby</a> (197MB, 3,281 files, 918,052 LOC)</li><li><a href=https://github.com/python/cpython>Python 3</a> (382MB, 3,570 files, 931,814 LOC)</li></ol><p>Unfortunately due to vagaries in the build process with Postgres, Apache Httpd, Ruby, and Python I can only report on Redis and Nginx. But more on that later.</p><p>The workload code can be found at <a href=https://github.com/bbengfort/compile-workload>github.com/bbengfort/compile-workload</a> along with a <a href=https://github.com/bbengfort/compile-workload/blob/master/benchmark.sh>benchmark.sh</a> script that executes the full test-suite. Here are the time results for the OS X file system (OS X) vs. MemFS for both cloning and compiling:</p><p><img loading=lazy src=/images/2017-01-30-clone-time.png alt="MemFS vs. Disk Clone Times"></p><p><img loading=lazy src=/images/2017-01-30-build-time.png alt="MemFS vs. Disk Build Times"></p><p>As you can see from the graphs, git clone is <em>horribly</em> slow on MemFS. Further investigation revealed that git is writing 4107 bytes of data at a time as it downloads its compressed pack file. This means approximately 255 times more calls to the <code>Write()</code> FUSE method than other file writing mechanisms which typically write 1MB at a time. Because each call to <code>Write()</code> must be handled by the FUSE server and responded to by MemFS (which is allocating an byte slice under the hood), the more calls to <code>Write()</code> the exponentially worse the system is.</p><p>Compiling, on the other hand, is supposed to be more representative of a workload - containing many reads, writes, and stats in a controlled sequence of events. For both Redis and Nginx, MemFS does add some overhead to compilation, but not nearly as much as git clone did. Note that downloading a zip file from GitHub and then building it exhibited a similar shape to the compiling graph.</p><p>Memory usage for MemFS is currently atrocious, however:</p><p><img loading=lazy src=/images/2017-01-30-mprof-memfs.png alt="MemFS vs. Disk Memory Usage"></p><p>The dotted lines are the maximum file usage on disk according to a recursive stat of each file. The solid lines are the memory usage of MemFS during clone and build. Although some extra memory overhead is expected to maintain the journal and references to the file system tree, the amount of overhead necessary seems completely out of whack compared to the storage requirements. Some investigation about freeing data is necessary.</p><p>Finally the last, critical lesson. The reason only Redis and Nginx are represented in the graph is because the other builds failed for one reason or another. The cause of the build failures is primarily due to my goal to implement 100% of the FUSE interface methods. <strong>However this is not how bazil.org/fuse works and in fact 100% interface implementation is exactly the wrong thing to do.</strong></p><p>Take for example the <code>ReadAll()</code> vs. <code>Read()</code> methods that implement <code>HandleReadAller</code> and <code>HandleReader</code> respectively. I attempted to implement both and kept receiving different build errors, though I did notice the clone and compile behavior changing as I messed with these two methods. It turns out that the bazil.org/fuse <a href=https://github.com/bazil/fuse/blob/master/fs/serve.go#L1228>server implementation</a> checks to see if the FS implements <code>HandleReadAller</code> and if so, returns the result from <code>ReadAll</code>, otherwise it enforces <code>HandleRead</code> and sends the <code>Read</code> method the request and response from FUSE.</p><p>My hypothesis as to why cloning was failing when I had implemented <code>ReadAll</code> is simple. The <code>Read</code> method allows the client to specify an offset in the file to read from and a size of data to respond with. Presumably git clone was attempting to read the last 32 bytes of the compressed pack file (or something like that) so it could perform a CRC check or some other data validation. FUSE, however, returned <em>all</em> of the data rather than just the data from the offset because <code>ReadAll</code> was implemented. As a result, git clone choked with a stream error.</p><p>The bottom line is that FUSE allows some interfaces for convenience only for higher level FS implementations. MemFS, however, needs to support only the low level FUSE serve interactions. As a general rule of thumb, if the interface method takes a request and response object and simply returns an error - then that FUSE method is probably at a bit lower of a level, exactly what MemFS is looking for.</p></div><footer class=post-footer></footer></article></main><footer class=footer><span>&copy; 2021 <a href=https://bbengfort.github.io>Libelli</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById('menu')
menu.scrollLeft=localStorage.getItem("menu-scroll-position");menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft);}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>